The Intel 486DX is, of course, not solely a coprocessor. This chip, first introduced by Intel in 1989, functionally combines the CPU (a heavily-pipelined implementation of the 386 architecture) with an enhanced 387 (the chip's floating-point unit, FPU) and 8 KB of unified on-chip code/data cache. (This description is necessarily simplified; for a detailed hardware description, see [52].) The 486DX offers about two to three times the integer performance of a 386 at the same clock frequency, while floating-point performance is about three to four times as high as the Intel 387DX at the same clock rate [29]. Since the FPU is on the same chip as the CPU, the considerable communication overhead between CPU and coprocessor in a 386/387 system is omitted, letting FPU instructions run at the full speed permitted by the implementation. The FPU also takes advantage of the on-chip cache and the highly pipelined execution unit. The concurrent execution of CPU and coprocessor instructions typical for 80x86/80x87 systems is still in existence on the 486, but some FPU instructions like FSIN have nearly no concurrency with CPU instructions, indicating that they make heavy use of both, CPU and FPU resources [53, 1].

Tague explains that there had been local mechanization of processes but not large scale integration of the mechanization. "Take repair," he suggests as an example, "A lot of it deals with keeping the connections straight between what we call the main distribution frames in the central office and the wires that tie residential telephones into the switch. Prior to the use of computers, `mechanization' consisted of somebody on a remote test bench using electrical meters and instruments to test lines. To get those connections made, an intercom was used to broadcast requests to a bunch of people standing around with alligator clips and soldering irons down in the wire center. The requests went something like, `Would you kindly connect jumper x to terminal y?' to get testing done."(Ibid, p. 60)

Memory chips are rated at speeds of 70-200 nanoseconds. A nanosecond is a billionth of a second which means that such chips are capable of speed comparable to CPU speeds. That the speeds are slightly less is shown by the need for "wait states", which slow down the CPU to allow access to memory at its speed; RAM speeds, however, are roughly equal to those of the CPU. I/O speeds are considerably less. Even a fast hard disk rated at 20 milliseconds has a rated speed 100,000 times the speeds associated to RAM. Of course, because the RAM speed is a statement about each access and hard disk access times involve the first access of a disk sector, the actual ratios are not that bad.

in your config.sys file. Here nn is the number of buffers that you want and the recommended numbers tend to be from 15 to 20.

On the basis of time tests alone, it is difficult to pick one among these programs. Your choice will have to depend on factors like the amount of conventional memory they use, the particular characteristics of your system as they relate to issues like read ahead, and price.

With the research breakthrough of a portable computer operating system, "the first UNIX applications were installed in 1973 on a system involved in updating directory information and intercepting calls to numbers that had been changed. The automatic intercept system was delivered for use on early PDP-11s. This was essentially the first time UNIX was used to support an actual, ongoing operating business." (Mohr, pg. 26)

"From the support point of view," he continues, "such a capability would solve a very important problem. Without UNIX and its potential portability, the people building the operations support systems were faced with selecting an outside vendor that could supply the hardware on which to get their devlopment done. Once that was complete, they would be locked into that vendor." However, according to Mohr, "Portability obviated this limitation and offered a number of other advantages. When making a hardware upgrade, even to equipment from the same vendor, there are variations version to version. That could cost a lot of money in software revisions unless there were some level of portability already written into the scenario." (Ibid., pg. 24-25)

Considering the coprocessor emulators, the Franke387 has acceptable accuracy for the FSIN, FCOS, and FPATAN instructions, taking into consideration that according to its documentation, Franke387 uses only 64 bits of precision for the intermediate results, while coprocessors typically use 68 bits and more. However, the larger error in the FPTAN, F2XM1, FYL2XP1, and especially the FYL2X operations show that the emulator doesn't use state-of-the-art algorithms, which ensure an error of only a very few ULPs even if no extra precise intermediate results are available. Microsoft's emulator, meanwhile, provides transcendental functions with rather good accuracy, except for the logarithmic operations, which contain some minor flaws. The Q387 emulator, which came out only recently and is the fastest emulator available, could unfortunately not be tested since it caused TRANCK to abort with a GP (general protection) fault for every input that I tried.

The Weitek 3167 and 4167 coprocessors only implement the basic arithmetic functions (add, subtract, multiply, divide, square root) in hardware; transcendental functions are implemented by means of a software library supplied by Weitek which uses the basic hardware instructions to approximate the transcendental functions (using polynomial and rational approximations). The clock cycle timings for the transcendental functions are average values, since execution time can differ with the value of argument. The speed of transcendental functions for the 4167 is estimated based on the numbers in [31,33], from which this timing information has been extracted.

If you want to push your 386-based system to its maximum floating-point performance and can't switch to a 486, I recommend the Intel RapidCAD chipset. It is both faster [1] and cheaper than installing a Weitek Abacus 3167 in a 386 system, which used to be the highest performing combination before the RapidCAD was introduced.

Hello, before we begin I need to tell you that we will be using the program listing that was in last months GAZZETTE, the program that was in the library file has the name of 'ROOMS.BAS'. We will be talking line numbers and you will probably need a listing handy to make much sense out of this months ramblings, so I will wait here while you get a listing.

The kernel was conceived as what was essential and other features were left to be developed as part of the tools or software that would be available. Thompson explains:

The test results show that the IIT 3C87 does not conform to the IEEE-754 floating-point standard in that it does not support denormals in double extended precision. The ULSI 83C87 does not conform to that standard in that it does not support precision control, but uses double extended precision for all operations. The TP 6.0 emulator supports neither precision control, rounding control nor support for any denormals, as does the Q387 emulator. In addition, their basic arithmetic operations do not seem to conform to the IEEE standard as the results of the test programs differ from that of any result computed by a coprocessor for any mode.

(ii) Expect the output of every program to become the input to another, as yet unknown, program. Don't clutter output with extraneous information. Avoid stringently columnar or binary input formats. Don't insist on interactive input.

The need was also recognized for "a common operating environment between projects." (Ibid.,p. 50-52) "Major additions" he writes, "necessary to move the timeshared UNIX system into real-time applications included interprocess communications (name pipes, messages, semaphores, and shared memory), file access (logical file system, record access system), error recovery, power fail/restart, and line and terminal disciplines. These additions were developed, integrated or donated to the common good by people developing specific systems. By 1979," he reviews, "there was an enhanced real-time UNIX system that was centrally supported, offering a collection of tools and a number of human/machine interface designs to protect system users from direct contact with UNIX primitives." (Ibid, p. 52)

As head of the Computer Planning Department, Tague had been responsible for systems engineering. In 1971 Tague garnered support for UNIX to be adopted. Then he pushed to have UNIX made the internal standard and to provide central support through his organization. By September, 1973, he was able to form a development organization to provide support for a "standard Unix." This group, called UNIX Development Support worked with Bell Labs Research. Though the two groups sometimes diverged regarding their priorities, Mohr explains that they agreed on the need for UNIX portability.

"(i) Make each program do one thing well. To do a new job, build afresh rather than complicate old programs by adding new features.

Cuilwik describes how the need for such real time applications was determined in the 1969-70 period, just when UNIX was being created. Development, he reports, "began in earnest in 1971. Early in this period," he writes, "it was determined that an operating system and environment should be provided to system designers, who would then only need to develop application-specific software." By 1974, he reports "several sites had chosen the UNIX operating system as this development environment. A few, meanwhile, had also selected it as an execution environment and were busy designing enhancements and improvements for the system." (Ibid.)

There are software tools to try to speed up I/O especially by using RAM for certain operations. This month, I'll discuss one category of those tools -- disk caches; programs that can substantially speed up disk access.

Whetstone [2,3,4] is a synthetic benchmark based upon statistics collected about the use of certain control and data structures in programs written in high level languages. Based on these statistics, it tries to mirror a 'typical' HLL program. Whetstone performance is expressed by how many hypothetical 'whetstone' instructions are executed per second. It was originally implemented in ALGOL. Unlike PEAKFLOP, LLL, and Linpack, Whetstone not only uses addition and multiplication but exercises all basic arithmetic operations as well as some transcendental functions. Whetstone performance depends on the speed of the CPU as well as on the coprocessor, while PEAKFLOP, LLL, and Linpack place a heavier burden on the coprocessor/FPU.

During the formative years in the creation of the Arpanet, which was to become the backbone to the Global Computer Network, there were similar seminal developments taking place at the Bell Laboratories, the Research and Development unit of the Bell System. These developments were to have a significant impact on the future course of computer science research and networking in the world. As early as 1957, Bell Labs found they needed an operating system for their inhouse computer center which was then running lots of short batch jobs. Describing the situation facing the Labs, Victor Vyssotsky, who had been involved the techanical head of the Multics project at Bell Labs and later Executive Director of Research in the Information Systems Division of AT&T Bell Labs, explains, " We just couldn't take the time to get them on and off the machine manually. We needed an operating system to sequence jobs through and control machine resources." (from "Putting Unix in Perspective", Interview with Victor Vyssotsky, by Ned Pierce, in Unix Review, Jan. 1985, p. 59)

There is a second warning that needs to be made about using these programs with AT extended memory, an option that is only available with Polyboost, Super PC-Kwik and Vcache. Unfortunately, there is no memory management protocol for AT extended memory provided by the current versions of DOS. This lack of a standard means there is potential for programs that you try to load there to not know of each others existence and to therefore overwrite each other. Since IBM publishes the source code for VDISK, all these programs know about its protocol and can avoid clobbering it. The situation is not so good for other virtual disk programs. I've seen complaints about problems with AST's SUPERSPL program and I've had problems with a cache in extended memory overwriting a RAM disk set with the RAMDRV program included with Microsoft Windows and with some versions of MS-DOS. It is unfortunate that Microsoft has not published the specifications that this program uses to access extended memory. So, if you are using any other programs in extended memory and using an extended memory cache, be sure to check out the operation of the other programs after the cache is loaded. Super PC-Kwik and Vcache have a command line parameter which you can use to give the program an absolute address in extended memory at which to load and so avoid the conflict "by hand". That they have to resort to such a kludge speaks to the rather sorry state of extended memory support in DOS 3.x.

o Extended memory, the memory above 1 megabyte (up to 16 megabytes) that is accessible by 80286 computers. This memory is not normally accessible for use as conventional memory but is generally used for RAM disks, disk caches or print spoolers.

While the times on EGA/CRTBOOST are impressive, it has some bugs. When EGABOOST was installed, even with its speed parameter set to the slowest value (1), I was unable to change monitors on a two monitor system with either DOS' MODE command or a public domain program that I use. There are programs that require me to use Fansi's capability to turn Q=1 on and off from BATch files. These programs do not work properly with CRTBOOST at its highest settings. You can change to a setting where they do work but only with a menu driven utility. Finally, both CRTBOOST and VSCREEN suffer from the defect that screen speedup can be a disadvantage if you don't also have screen scrolling memory. I have not tested all screen scrolling memory programs with these two speedup programs but I'd expect at least some incompatibilities. Fansi comes with its own screen scrolling memory which even supports EMS.

The Cyrix 486DLC is the latest entry into the market of 386DX replacement processors. It features an Intel 486SX-compatible instruction set, a 1 KB on- chip cache, and a 16x16 bit hardware multiplier. The RISC-like execution unit of the 486DLC executes many instructions in a single clock cycle. The hardware multiplier multiplies 16-bit quantities in 3 clock cycles, as compared to 12-25 cycles on a standard Intel 386DX. This is especially useful in address calculations (code from non-optimizing compilers may contain many MUL instructions for array accesses) and for software floating-point arithmetic. The 1 KB cache helps the 486DLC to overcome some of the limitations of the 386 bus interface, and although its hit rate averages only about 65% under normal program conditions, a 5-15% overall performance increase can usually be seen for both integer and floating-point-intensive applications when it is enabled.

What is the proper size? That's a trade off-between what else you want to use your RAM for and how you use your machine. I have the impression that unless your cache is at least 60K, you may be better served by DOS buffers although for some operations, a 20K cache will show a noticeable improvement.

With the loss of the Multics experimental operating system, Ken Thompson, Dennis Ritchie and the others at the Labs who began work on UNIX, realized they had to focus on creating an operating system for their programming needs. "I don't think," Vyssotsky relates, "that either of them was particularly fascinated by operating systems until they found themselves cast back upon GECOS. They sort of got interested in the subject out of self defense."(Ibid.)

If you are interested in programming techniques which allow the detection and differentiation of the coprocessors described above, I refer you to my COMPTEST program. COMPTEST reliably detects the type and clock frequency of the CPU and coprocessor installed in your machine. The current version is CTEST257.ZIP, with future versions to be called CTEST258, CTEST259 and so on. COMPTEST can correctly identify all of the coprocessors described above, with the exception of the Weitek chips, for which the detection mechanism is not that reliable.

8087 and 287 coprocessors have a notch on one the shorter sides of their rectangular DIL package that should be matched with the notch of the coprocessor socket. Usually the 286 CPU and the 287 coprocessor are placed alongside each other and both have the same orientation, (that is, their respective notches point in the same direction). 387SX coprocessors feature a white dot or similar mark that matches with some sort of marking on the socket. 387 coprocessors have a bevelled corner that is also marked with a white dot or similar marking. This should be matched with the bevelled or otherwise marked corner of the socket. If your system has only a large EMC socket and you are installing a 387 in it, you will leave one row of pin holes free on each side of the chip.

Besides being slow, coprocessor emulators have other drawbacks when compared with real coprocessors. Most of the emulators do not support the additional instructions that the 387-compatible coprocessors offer over the 80287. Often, some of the low-level stack-manipulating instructions like FDECSTP are not emulated. For example, [76] lists the coprocessor instructions not emulated by Microsoft's emulator (included in the MS-C and MS-FORTRAN libraries) as follows:

You can also cut down on access to a physical disk by using a RAM disk, that is by setting aside a part of RAM as a virtual disk which DOS accesses as if it were an ordinary disk. There are several differences between RAM disks and disk caches. Accessing files from a RAM disk is often slightly faster as our time tests will show. Moreover, the first access of a file with a cache will be slower than later accesses. On the negative side, you must decide in advance which files you'll want on the RAM disk; you'll also have to be sure to copy any changed data files from the RAM disk to a real disk or risk losing them when you power down or if your system crashes.

These documents may reside anywhere in the Internet and are known as "hypermedia" -- information that is linked together (hypertext) presented with graphics, movies, and sounds (multimedia). A Uniform Resource Locator (URL) is used to specify some piece of information on the Web. The URL for the Skydive! WWW site mentioned above is

By 1969, however, AT&T made a decision to withdraw from the project. Describing that period, Dennis Ritchie, another of the inventors of unix at Bell Labs writes, "By 1969, Bell Labs management, and even the researchers came to believe that the promises of Multics could be fulfilled only too late and too expensively." (from Dennis Ritchie, "The Development of the C Language," ACM, presented at Second History of Programming Languages conference, Cambridge, Mass, April 1993, p. 1)

Originally, Cyrix claimed support for the fast memory-mapped mode of the EMC87 from a number of software vendors (including Borland and Microsoft). However, there are only very few applications that make use of it, among them Evolution Computing's FastCAD 3D, MicroWay Inc.'s NDP FORTRAN-386 compiler, Metaware's High-C compiler version 1.6 and newer, and Intusofts's Spice [63,73]. Part of the problem in supporting the memory-mapped mode is that the application must reserve one of the general purpose registers of the CPU to use memory-mapped mode instructions that access memory.

Once loaded, cache programs act in the background and require no action or input from the user. But some of these programs have option switches which you'll need to study carefully to load the program to operate in an optimal manner. For many, the defaults will be correct, but you'all at least want to adjust the cache size.

Tests 9, 10 and 11 are Norton's disk test program on a hard disk, 1.2 megabyte floppy, and regular floppy, respectively. The Norton tests are included because the results are so dramatic. These dramatic speed increases over DOS are due mainly to read ahead as can be seen by running Super PC-Kwik with this option turned off. The copy tests check on whether there is time lost because of cache overhead.

Each program they built developed some simple capability and they called that program a tool. They wanted the programs to be fun to use and to be helpful to programmers. Describing the achievements of the lab, Doug McIlroy, one of the researchers and Thompson's Dept Head when they created UNIX, describes the atmosphere at the lab:

Tests I ran with the IEEETEST program show that the 3C87 is not fully compatible with the IEEE-754 standard for floating-point arithmetic, although the manufacturer claims otherwise. It is indeed possible that the reported errors are due to personal interpretations of the standard by the program's author that have been incorporated into IEEETEST and that the standard also supports the different interpretation chosen by IIT. On the other hand, the IEEE test vectors incorporated into IEEETEST have become somewhat of an industry standard [66] and Intel's 387, 486, and RapidCAD chips pass the test without a single failure, so the fact that the IIT 3C87 fails some of the tests indicates that it is not fully compatible with the Intel 387 coprocessor. My tests also show that the IIT 3C87 does not support denormals for the double extended format. It is not entirely clear whether the IEEE standard mandates support for extended precision denormals, as the IEEE-754 document explicitly only mentions single and double-precision denormals. Missing support for denormals is not a critical issue for most applications, but there are some programs for which support of denormals is at the very least quite helpful [41]. In any case, failure of the 3C87 to support extended precision denormal numbers does represent an incompatibility with the Intel 387 and 486 chips.

The BESYS operating system was created at Bell Labs to deal with their inhouse needs. When asked by others outside the labs to make a copy available, they did so but with no obligation to provide support. "There was no support when we shipped a BESYS tape to somebody," Vyssotsky recalls, "we would answer reasonable questions over the telephone. If they found troubles or we found troubles, we would provide fixes." (Ibid., p. 59)

Since the EMC87 provides also the standard 386/387 CPU interface via IO ports, it can be used just like any other 387-compatible coprocessor and delivers the same performance as the Cyrix 83D87 in this mode. The EMC87 even allows mixed use of memory-mapped and traditional instructions in the same code. Cyrix has also implemented some additional instructions in the EMC87 that are also available in the 387-compatible mode: FRICHOP, FRINT2, and FRINEAR. These instructions enable rounding to integer without setting the rounding mode by manipulating the coprocessor control word, and are intended to make life easier for compiler writers.

Note that coprocessor performance also depends on the motherboard, or more specifically, the chipset used on the motherboard. In [34] and [35] identically configured motherboards using different 386 chipsets were tested. Among other tests a coprocessor benchmark was run which is based on a fractal computation and its execution time recorded. The following tables showing coprocessor performance to vary with the chipset have been copied from these articles in abridged form:

The CPU used in testing the 387 coprocessors was an Intel 386DX. Note that due to the improved coprocessor interface of the Cyrix 486DLC the execution time of most coprocessor instructions drops by 2-3 clock cycles when used with this CPU.

SAVAGE tests the performance of transcendental function evaluation. It is basically a small loop in which the sin, cos, arctan, ln, exp, and sqrt functions are combined in a single expression. While sin, cos, arctan, and sqrt can be evaluated directly with a single 387 coprocessor instruction each, ln and exp need additional preprocessing for argument reduction and result conversion. According to [14], the Savage benchmark was devised by Bill Savage, and is distributed by: The Wohl Engine Company, Ltd., 8200 Shore Front Parkway, Rockaway Beach, NY 11693, USA. Usually, Savage is programmed to make 250,000 passes though the loop. Here only 10,000 loops are executed for a total of 60,000 transcendental function evaluations. The result is expressed in function evaluations per second. SAVAGE source code was taken from [7] and compiled with Turbo Pascal 6.0 and my own run-time library (see above).

According to Mohr, "Tague foresaw the possiblity of UNIX becoming an inteface between hardware and software that would allow applications to keep running while the hardware underneath was changing." (Ibid., p. 24)

"Moreover, for people like Ken Thompson," Vyssotsky emphasizes, "having this embryonic version of Multics taken away and GECOS slapped down in its place was something of a disaster. Suddenly they were back to square one."(Ibid.)

For the IIT 3C87, a special version of TRNSFORM was written that makes use of the special F4X4 instruction available on that coprocessor. F4X4 does a full multiplication of a 4x4 matrix by a 4x1 vector in a single instruction. TRNSFORM is implemented as an optimized assembler program linked with the Turbo Pascal 6.0 library. The full source code can be found in appendix B.

Using this special mode of the EMC87 provides a significant speed advantage. The traditional 387 CPU-coprocessor interface via IO ports has an overhead of about 14-20 clock cycles. Since the Cyrix 83D87 executes some operations like addition and multiplication in much less time, its performance is actually limited by the CPU-coprocessor interface. Since the memory-mapped mode has much less overhead, it allows all coprocessor instructions to be executed at full speed with no penalty.

The result, Ritchie explains, was that "Thompson's PDP-7 assembler outdid even DEC's in simplicity; it evaluated expressions and emitted the corresponding bits. There were no libraries, no loader or link editor: the entire source of a program was presented to the assembler, and the output file -- with a fixed name -- that emerged was directly executable.(Ibid., pg. 2)

Operating systems such as OS/2 2.0 and Windows 3.1 provide coprocessor emulations using INT 7 automatically if they do not find a coprocessor to be installed. The emulator in Windows doesn't seem to be very fast, as people who have ported their Turbo Pascal programs from the TP 6.0 DOS compiler (using the emulation built into the TP 6.0 run-time library) to the TPW 1.5 Windows compiler (using MS Windows' emulator) have noticed. Slowdowns of as much as a factor of five have been reported [79].

To add floating-point capabilities to a 486SX based system, it would seem to be easiest to swap the 486SX for a 486DX, which includes the FPU on-chip. However, Intel has prevented this easy solution by giving the 486SX a slightly different pin out [48, 51]. Since only three pins are assigned differently, clever board manufacturers have come out with boards that accept anything from a 486SX-20 to a 486DX2-50 in their CPU socket and by doing so provide a clean upgrade path. A set of three jumpers ensures correct signal assignment to the changed pins for either CPU type. To upgrade 486SX systems without this feature, you are forced to buy a 487SX and install it in the "Performance Upgrade Socket" (present in most systems).

You may have heard the phrase "surfing the 'net" which means navigating the vast information resources of the Internet. With all the skydiving information available online, you might just consider surfing the 'net yourself -- skysurfing that is.

To the main CPU, the Weitek Abacus appears as a 64 KB block of memory starting at physical address 0C0000000h. Each address in this range corresponds to a coprocessor instruction. Accessing a specified memory location within this block with a MOV instruction causes the corresponding Weitek instruction to be executed. (The instructions have been cleverly assigned to memory locations in such a way that loads to consecutive coprocessor registers can make use of the 386/486 MOVS string instruction.) This memory-mapped interface is much faster than the IO-oriented protocol that is used to couple the CPU to an 80287 or 80387 coprocessor. The Weitek's memory block can actually be assigned to any logical address using the MMU (memory management unit) in the 386/486's protected and virtual modes. This also means that the Weitek Abacus *cannot* be used in the real mode of those processors, since their physical starting address (0C0000000h) is not within the 1 MByte address range and the MMU is inoperable in real mode. However, DOS programs can make use of the Weitek by using a DOS extender or a memory manager (such as QEMM or EMM386) that runs in protected/virtual mode itself and can therefore map the Weitek's memory block to any desired location in the 1 MByte address range.

; MUL_4x4 multiplicates a four-by-four matrix by an array of four ; dimensional vectors. This operation is needed for 3D transformations ; in graphics data processing. There are arrays for each component of ; a vector. Thus there is an ; array containing all the x components, ; another containing all the y components and so on. Each component is ; an 8 byte IEEE floating-point number. Two indices into the array of ; vectors are given. The first is the index of the vector that will be ; processed first, the second is the index of the vector processed ; last.

To get the best of both worlds, one might want to use a Weitek 3167 and a 387 compatible coprocessor in the same system. These coprocessors can coexist in the same system without problems; however, most 386-based systems contain only one coprocessor socket, usually of the EMC (extended math coprocessor) type. Thus, you can install either a 387 coprocessor or a Weitek 3167, but not both at the same time. There *are* small daughter boards available that plug into the EMC socket and provide two sockets, an EMC and a standard coprocessor socket.

Usually, installing a coprocessor doesn't pose much of a problem, as every coprocessor comes with installation instructions and a diagnostic disk that lets you check its correct operation after installation. In addition, the user manuals of most computers have a section on coprocessor installation.

"The discovery that we had the need -- or actually, the opportunity -- in the early '70s to use these minis to support telephone company operations encouraged us to work with the UNIX system," confirms Berkley Tague. ("Interview with Berkley Tague," Unix Review, June 1985, p. 59) "We knew we could do a better job with maintenance, traffic control, repair, and accounting applications." (Ibid.)

"UNIX came into many CS departments largely because it was the only powerful interactive system that could run on the sort of hardware (PDP-11s) that universities could afford in the mid '70s. In addition, UNIX itself was very inexpensive. Since source code was provided, it was a system that could be shaped to the requirements of a particular installation. It was written in a language considerably more attractive than assembly, and it was small enough to be studied and understood by individuals."

Since neither a Weitek coprocessor nor a compiler that generates code for the Weitek chips were available to me, performance data for the Weitek Abacus is given here according to [31,32] and scaled to show performance of a 33 MHz system. The benchmarks were compiled using highly-optimizing 32-bit compilers.

You should be careful to distinguish between a disk cache and memory caches. There are circumstances where it may happen that some of your RAM runs at a higher speed than most of your RAM. In that case, it may pay to cache some of the reading of instructions from the slow RAM to speed up programs with loops. Two situations are where you add a speedup (usually 80186- or 80286-based) board to a PC with lots of old RAM typically at 200 nanoseconds or with 386 machines where RAM that keeps up with the processor should be rated at 100 or even 70 nanoseconds. In any event, these situations involve a memory cache, not a disk cache which is the subject of this article.

When I first started using a cache, I found the experience eerie. I'd do some action that I often did and wondered why my disk access light wasn't going on.

All the tests are done on a Kaypro 286i with a Xebec EMS board. To check how much overhead EMS causes, I ran the tests for Super PC-Kwik in both EMS and conventional memory. This overhead is due to the lack of DMA support in EMS and not to the bank switching. Since I could not get Quickcache and Speedcache to run under this EMS setup, I did their tests in conventional memory which gives them a slight advantage. I used the recommended number of DOS buffers with buffers=20 in those cases with no recommendation about decreasing the number of buffers. I used 256K of cache. For all the tests but Tests 8, 10 and 11, the cache was only hard disk for those programs (Polyboost, Vcache) with separate diskette caches. For Vcache, I used a 240K vs. 24K split between disk and diskette caches and for Polyboost, which requires separate caches for each diskette, I used a 256K hard disk cache and 16K for each diskette.

Information on the Usenet is hierarchically organized into "newsgroups." There are hierarchies for computers, recreation, science, and all kinds of information. For example, "comp.lang.c" is for the C programming language, and "sci.astro" is the scientific newsgroup for astronomy.

The Weitek coprocessors have a RISC-like architecture which has been tuned for maximum performance. Only a small instruction set has been implemented in the chip, but each instruction executes at a very high speed (usually only a few clock cycles each). Instructions available include load/store, add, subtract, subtract reverse, multiply, multiply and negate, multiply and accumulate, multiply and take absolute value, divide reverse, negate, absolute value, compare/test, convert fix/float, and square root. In contrast to the 80x87 family, the Weitek Abacus does not support a double extended format, has no built-in transcendental functions, and does not support denormals. The resources required to implement such features have instead been devoted to implement the basic arithmetic operations as fast as possible.

Evaluating the influence of the MULTICS research on Bell Labs researchers, Comer points out that top researchers in computer science and mathematics from the world's premier industrial research center, Bell Labs, were able to work with top researchers from academia. When Ken Thompson, Dennis Ritchie and their "Bell Laboratories colleagues," writes Comer, "later began work on their own implementation of a Multics-like time-sharing system, they drew heavily from the Multics experience. So, despite popular myth, UNIX was not an accidental discovery at all -- it evolved directly from experiences with academic research." (Ibid., p. 41-42)

Both LLL and Whetstone results (see below) are reported as returned by my COMPTEST test program, in which they have been included as a measure of coprocessor/FPU performance. COMPTEST has been compiled under Turbo Pascal 6.0 with all 'optimizations' on and using my own run-time library, which gives higher performance than the one included with TP 6.0. My library is available as TPL60N18.ZIP from garbo.uwasa.fi and ftp sites that mirror this site.

The operating system was named UNIX, to distinguish it from the complexity of MULTICS. Vyssotsky recalls that in addition to Thompson and Ritchie, "the two most active contributors at that stage were Joe Ossanna and Rudd Canaday. I should also add," he explains, "that Doug McIlroy was tremendously influential on their thinking."(Vyssotsky, pg.60) Vyssotsky elaborates, "I don't think that Doug actually contributed much of the programming, but for example, the appearance of pipes in UNIX was clearly a result of Doug's discussions with Ken and Dennis." (Ibid. ) Ken put them in, but "it was McIlroy who said, "Look you ought to do it. Pipes, like most things in UNIX were not a radically new idea. Co-routines had, after all, shown up in SIMULA by the end of 1967."(Ibid.)

Most GUIs (graphical user interfaces) such as Microsoft Windows or the OS/2 Presentation Manager do *not* gain additional speed from using a *mathematical* coprocessor, since their graphics operations only use integer arithmetic [71]. They *will* benefit from a graphics board with a graphics "coprocessor" that speeds up certain common graphics operations such as BitBlt or line drawing. A few GUIs used on PCs, such as X-Windows, use a certain amount of floating-point operations for operations such as arc drawing. However, the use of floating-point operations in X-Windows seems to have decreased significantly in versions after X11R3, so the overall performance impact of a coprocessor is small [72]. Applications running under any GUI may take advantage of a math coprocessor, of course (for example, Microsoft Excel running under Windows).

The performance statistics below were put together with the help of four widely-known numeric benchmarks and two benchmarks developed by me. Three Pascal programs, one FORTRAN program, and two assembly language programs were used. The assembly language programs were linked with Borland's Turbo Pascal 6.0 for library support, especially to include the coprocessor emulator of the TP 6.0 run-time library. The Pascal programs were compiled with Turbo Pascal 6.0, a non-optimizing compiler that produces 16-bit code. The FORTRAN program was compiled using Microsoft's FORTRAN 5.0, an optimizing compiler that generates 16-bit code. All programs use double-precision variables (except PEAKFLOP and SAVAGE, which use double extended precision).

This document has been created to provide the net.community with some detailed information about mathematical coprocessors for the Intel 80x86 CPU family. It may also help to answer some of the FAQs (frequently asked questions) about this topic. The primary focus of this document is on 80387- compatible chips, but there is also some information on the other chips in the 80x87 family and the Weitek family of coprocessors. Care was taken to make the information included as accurate as possible. If you think you have discovered erroneous information in this text, or think that a certain detail needs to be clarified, or want to suggest additions, feel free to contact me at:

The 8087/8087 combination can be characterized as a cooperation of partners with equal rights, while the 80286/287 is more a master-slave relationship. This makes synchronization easier, since the complete instruction and data flow of the coprocessor goes through the CPU. Before executing most coprocessor instructions, the 80286 tests its /BUSY pin, which is tied to the 287 coprocessor and signals if the 80287 is still executing a previous coprocessor instruction or has encountered an exception. The 80286 then waits until the /BUSY signal goes to "low" before loading the next coprocessor instruction into the 80287. Therefore, a WAIT instruction before every coprocessor instruction is not required. These WAITs are permissible, but not necessary, in 80287 programs. The second form of WAIT synchronization (after the coprocessor has written a memory operand) *is* still necessary on 286/287 systems.

This change affected workers like those "plugging in an alternate module or pulling a manual switch and going to a backup system," he clarifies. "Suddenly, their work became much faster because the information was all in one place -- unlike earlier days when eight guys would have had to collect and sort out the trouble data in a series of phone calls before actually being able to get down to the business of working on solutions." (Ibid.)

As previously noted, the Weitek Abacus 3167 and 4167 coprocessors implement only the basic arithmetic operations (add, subtract, negate, multiply, divide, square root) in hardware. Transcendental functions are performed via a software library provided by Weitek. For these library functions Weitek claims a maximum relative error of 5 ULPs [31,33]. This means that the last three bits in the mantissa of a double-precision result can be wrong. Note that the Intel 387 and compatible math coprocessors generate the transcendental functions with a small relative error with regard to the *extended double precision* format. Thus, when rounded to double-precision, their function values are nearly always 'exact'. The problem of 'double rounding' prevents them to be 'exact' in 100% of all cases. 387 type coprocessors in general have superior accuracy when compared with Weitek's coprocesssors.

5) Check your computer's manual for the proper position of any jumpers or switches that need to be set to tell the system it now has a coprocessor (and possibly, which kind it has). Put the cover back on the system unit, reconnect the power, and turn on your computer. Depending on your system's BIOS, you may now have to run a setup or configuration program to enable the coprocessor. Finally, run the programs supplied on the diagnostic disk (included with your coprocessor) to check for its correct operation.

Do not confuse keeping dirty buffers, that is delaying writing to disk, with caching writes. The latter means that the cache writes to disk but keeps a copy of the material which is written to disk if it is different from the copy that was read previously. For example, if you load a file in your word processor, change it and save it, a program that caches writes will save a copy of the final file version in its cache while one that does not, will not keep such a copy. All the commercial programs discussed in this article cache writes, but Emmcache does not.

On many systems, the motherboard is supported only at a small number of points. Since considerable force is required to insert a pin grid chip like the 80387, RapidCAD, or Weitek Abacus 3167 into its socket, the board may bend quite a lot due to the insertion pressure. This could cause cracks in the board's conductive traces that may render it intermittently or completely inoperable. Damage done to the board in this way is usually not covered by the computer's warranty! Therefore, it may be a good idea to first check how much the board bends by pressing on the math coprocessor socket with your finger. If you find it to bend easily, try to put something under the board directly beneath the coprocessor socket. If this is impossible, as it is in many desktop cases, consider removing the whole mother board from the case, and placing it on a hard, flat surface free of static electricity. (You will also have to do this if your system's CPU and coprocessor socket are on a separate card rather than on the motherboard, as is typical in many modular systems.)

1) What are math coprocessors? 2) How PC programs use a math coprocessor 3) Which applications benefit from a math coprocessor 4) Potential performance gains with a math coprocessor 5) How various math coprocessors work 6) Coprocessor emulator software 7) Installing a math coprocessor 8) Detailed description and specifications for all available math coprocessor chips 9) Finding out which coprocessor you have (the COMPTEST program) 10) Current coprocessor prices and purchasing advice 11) The coprocessor benchmark programs (performance comparisons of available math coprocessors using various CPUs) 12) Clock-cycle timings for each coprocessor instruction 13) Accuracy tests and IEEE-754 conformance for various coprocessors 14) Accuracy of transcendental function calculations for various coprocessors 15) Compatibility tests with Intel's 387DX / the SMDIAG program 16) References (literature) 17) Addresses of manufacturers of math coprocessors 18) Appendix A: Test programs for partial compatibility and accuracy checks 19) Appendix B: Benchmark programs TRNSFORM and PEAKFLOP

The first part of the URL (before the two slashes) specifies the method of access (http for WWW, ftp, gopher, etc.). The second is typically the address of the computer on which the data or service are located. Further parts may specify the names of files or perhaps the text to search for in a database.

As part of the automated maintenance system, Lesk created a UNIX program called UUCP (UNIX to UNIX copy) which made it possible to use a phone or hard wired connection to have one computer poll another computer and deliver the software.

"The existing systems were made up of people and paper," he relates, "The phone business was in danger of being overwhelmed in the early '70s with the boom of the '60s. There was a big interest then in using computers to help manage that part of the business. We wanted to get rid of all of those Rolodex files and help those guys who had to pack instruments and parts back and forth just to keep things going."

"What is or is not implemented in the kernel represents both a great responsibility and a great power. It is a soap-box platform on `the way things should be done.' Even so, if `the way' is too radical, no one will follow it. Every important decision was weighed carefully. Throughout, simplicity has been substituted for efficiency. Complex algorithms are used only if their complexity can be localized." (Ibid., p. 1931-2)

The IEEE-754 standard for floating-point arithmetic demands that processors and floating-point packages that can not store the result of operations *directly* to single and double precision location must provide precision control. The programs that test precision control and rounding control are designed to return a different result for each of the modes for the same sequence of operation.

Lions says about the freezing, "Much of the development of UNIX in Bell Laboratories occurred before 1978. After Edition 7, many of the original group went off to do other things. At the same time, UNIX was becoming important within the Bell System, which gave rise to a support group whose charter was to develop a polished and stable version of UNIX. This group was less interested in innovation than in stabilizing the system. Universities have simply picked up the slack. (Lions, pg. 56)

Test results for accuracy of transcendental functions for double extended precision as returned by the program TRANCK. 100,000 trials per function:

Tague describes how the mini computer made it possible to automate this process. "First, we were able to get more instructions out to the people actually making the connections. And, at the other end, we were able to centralize information about entire systems and end-to-end circuits."

Evaluating the achievement represented by the kernel, Vyssotsky explains, "I would say that the greatest intellectual achievement embedded in UNIX is the success Ken Thompson and Dennis Ritchie had in understanding how much you could leave out of an operating system without impairing its capability."(Vyssotsky, pg. 60-62)

(iv) Use tools in preference to unskilled help to lighten a programming task, even if you have to detour to build the tools and expect to throw some of them out after you've finished using them."

When the decision to pull out of the Multics project was made by AT&T, Vyssotsky explains there was an operating system that he called a "precursor of Multics" running on their GE 645 computer. "From the point of view of the few people who could use it," he notes, "it was a very nice programming environment. In particular, Ken Thompson thought it was a very nice programming environment."(Ibid.)

Not only for Ken Thompson's work, but for the research purposes of the Labs, an operating system more like what Multics had promised was needed. "I wanted a much more flexible system than BESYS or GECOS or OS360 or anything I could see," Vyssotsky recounts, "I had various things that I was trying to do with computers that were just plain hard to do with existing operating systems."(Ibid.)

Having access to the Internet usually means that one has access to a number of basic services: electronic mail, interactive conferences, access to information resources, network news, and the ability to transfer files. It also means that you, as an interested skydiver, have access to specific, up-to-date, and colorful information about your sport.

2) Always install a coprocessor that's rated at the same clock speed as the CPU. For example, in a 40 MHz 386 system using an AMD Am386-40, install a coprocessor rated for 40 MHz such as a Cyrix 83D87-40, C&T 38700DX-40, IIT 3C87-40, or ULSI 83C87-40. Running a coprocessor above its specified frequency rating may cause it to produce false results, which you might fail to recognize as such. (I have personally experienced this problem with a Cyrix 83D87-33 that I tried to push to 40 MHz. It passed all the diagnostic benchmarks on the Cyrix diagnostic disk and the tests of some commercial system test programs. However, I found it to fail the Whetstone and Linpack benchmarks, which include accuracy checks.) Although there is usually no problem with overheating when pushing a coprocessor over the specified maximum frequency rating, be warned that operation of a coprocessor above the maximum ratings stated by the manufacturer may make its operation unreliable.

Eventually the unix operating system was adopted in other departments at AT&T to do a variety of work. "There is one piece of history that I think is very important to understand," explains Vyssotsky, "When UNIX evolved within Bell Laboratories, it was not a result of some deliberate management initiative. It spread through channels of technical need and technical contact ... this was typical of the way UNIX spread around Bell Laboratories. You had MTSS Supervisors and Department Heads saying we had to go in this direction while Executive Directors were saying, `Well, I'm awful nervous about it. But if you guys say that is what we've got to do, I'll back your play."(Ibid, pg. 62-64)

Tague elaborates, "If we faced the phone company with 18 different vendors and 19 different environments, neither the developers nor the phone companies were going to be able to maintain the thing once it got out in the field in large numbers. As a planner, I was trying to focus on a few vendors. At that time, it was primarily Hewlett-Packard and DEC, plus a few IBM systems." (Tague, pg. 60)

While on the subject of time tests, I should mention that Lightning allows you to call up a screen which tells you how much time you have saved by using the cache. Its figures are pure fairy tale! I found that often it told me that I'd saved time in situations where I'd actually taken more time than using buffers=20. Presumably, it was using some algorithm giving me a comparison on some kind of slow 8088 based machine with buffers=2. Super PC-Kwik and Vcache will give you the more accurate listing of the number of accesses that have been from the cache as opposed to disk accesses.

Lightning has the annoying feature of using EMS memory if you have it, even if you'd prefer to use conventional memory; it does not support AT extended memory. As the name implies, Emmcache uses only EMS memory. Speedcache supports the special bank switching protocol on the Tall Tree JRAM boards as well as conventional and EMS memory. For the other programs, you'll have to decide whether your cache will reside in conventional, EMS or AT extended memory and how much memory it will take. Be warned that some of the programs default to rather unreasonable values of cache size, such as all the remaining EMS memory or all the conventional memory except for 232K for your remaining programs. Other parameters vary from program to program and concern things like what drives to cache and what algorithms to use in specific cases. For all but the what and how much memory to use, you can probably get away with using the defaults initially.

Lightning comes in both copy protected and unprotected versions; indeed, the price difference is so great that I'd call it ransomware. Because you'll want to load the program as part of your autoexec.bat and the copy protection is of the key disk version, you will really need the unprotected variety. All the other programs are not copy protected.

In my tests, the ULSI had the most inaccurate transcendental functions of all tested coprocessors. However, the maximum relative error is still within the limits set by Intel, so this is probably not an important issue for all but a very few applications. The ULSI 83C87 shows some minor flaws in the tests for IEEE 754 compatibility, but this, too, is probably unimportant under typical operating conditions. ULSI claims that the program IEEETEST, which was used to test for IEEE compatibility, contains many personal interpretations of the IEEE standard by the program's author and states that there is no ANSI- certified IEEE-754 compliance test. While this may be true, it is also a fact that the IEEE test vectors used in IEEETEST are a de facto industry standard, and that Intel's 387, 486, and RapidCAD chips pass it without a single failure, as do the coprocessors from Cyrix. Since the ULSI Math*Co 83C87 fails some of the tests, it is certainly less than 100% compatible with Intel's chips, although this will likely make little or no difference in typical operating conditions. (It is interesting to note that an ULSI 83S87 manufactured in 92/17 showed fewer errors in the IEEETEST test run [74] than the ULSI 83C87, manufactured in 91/48, I used in my original test. This indicates that ULSI might have applied some quick fixes to newer revisions of their math coprocessors.)

The 486DLC's internal cache is a unified data/instruction write-through type, and can be configured as either a direct mapped or a 2-way set associative cache. For compatibility reasons, the cache is disabled after a processor reset and must be enabled with the help of a small routine provided by Cyrix. Cyrix has also defined some additional cache control signals for some of the 486DLC pins, intended to improve communication between the on-chip cache and an external cache. Current 386 systems ignore these signals, since they are not defined for the standard Intel 386DX. However, future systems designed with the 486DLC in mind may take advantage of them for increased performance.

In keeping true to the UNIX community spirit of helping each other, Lions wrote a letter to Mel Ferentz, Lou Katz and others from Usenix and offered to make copies of his notes available to others. After some negotiation with Western Electric over the patent licensing, he distributed the notes titled "A Commentary on the UNIX Operating System" to others with UNIX licenses on the conditions that Western Electric had set out. (Ibid., p. 53)

o Frequently Asked Questions (FAQs) about skydiving o Airline travel with your rig o Federal Aviation Regulations (FARs) o World DZ price list and reviews o RW manuals o FAI dive pools o Skydiving movies and pictures (from jumpers worldwide) o Worldwide weather information o Links to other skydiving and general aviation sites

"Unix," he emphasizes, "was the distilled essence of operating systems, designed solely to be useful. Not to be marketable. Not to be compatible. Not to be an appendage to a particular kind of hardware. Moreover a computer running Unix was to be useful as a computer, not just a `platform' for canned `solutions'. It was to be programmable - cumulatively programmable. The actions of program builders were to be no different in kind from the actions of users; anything a user could do a program could do too...." (Ibid.)

Describing how research UNIX and its adoption at academic institutions has served to develop computer science, Doug Comer writes:

"UNIX had another appealing virtue that many may have recognized only after the fact -- its faithfulness to the prevailing mid-'70s philosophy of software design and development. Not only was UNIX proof that real software could be built the way many said it could, but it lent credibility to a science that was struggling to establish itself as a science. Faculty could use UNIX and teach about it at the same time. In most respects, the system exemplified good computer science. It provided a clean and powerful user interface and tools that promoted and encouraged the development of software. The fact that it was written in C allowed actual code to be presented and discussed, and made it possible to lift textbook examples into the real world. Obviously, UNIX was destined to grow in the academic community. (Ibid., p. 27)

John Lions, reviewing his experience as part of the UNIX community, concludes, "We have made a large number of contacts and exchanged a great deal of information around the world through this UNIX connection. Possibly that is the nicest thing about UNIX: it is not so much that the system itself is friendly but that the people who use it are. "(Lions, p. 57)

There's a lot of skydiving information out there on the Internet. I created a central index of information on what's called the World Wide Web (WWW), also known simply as "the Web." Documents on the Web can refer to virtually any kind of information resource on the Internet: Gopher/FTP/TELNET sites, Usenet newsgroups, and of course other Web sites. Examples of what you might find on the WWW site include:

"UNIX was not invented by hackers who were fooling around, nor did it take shape in a vacuum. It grew from strong academic roots and it has both nurtured and taken nourishment from academia throughout its development. The primary contributors to UNIX were highly educated mathematicians and computer scientists employed by what many people feel is the world's premier industrial research center, Bell Laboratories. Although they were knowledgeable and experienced in their own right, these developers maintained professional contacts with researchers in academia, leading to an exchange of ideas that proved beneficial for both sides. Understanding the symbiotic relationship between UNIX and the academic community means understanding the background of the system's inventors and the history of interactions between universities and Bell Laboratories." (Comer, p. 34, 42)

Besides being the fastest 387 coprocessor, the 83D87 also offers the most accurate transcendental functions results of all coprocessors tested (see test results below). The new "387+" version of the 83D87, available since November 1991, even surpasses the level of accuracy of the original 83D87 design. Note that the name 387+ is used in European distribution only. In other parts of the world, the new chip still goes by the name 83D87.

As with any culture, the culture of the Internet (sometimes called cyberspace) has its rules of good conduct or "netiquette." Like most things, it's best to listen for a while before speaking up. On the Internet, this is called "lurking." Lurk a newsgroup before posting your probable Frequently Asked Question. Look for a FAQ, which is a document most newsgroups collectively write to answer the most common questions, and read it completely before asking any questions. Otherwise you'll come off sounding like a whuffo.

There are many good books on the Internet these days, and some even come with software. Check out your local bookstore and try one out. Learn about the Internet before you speak up. Consider it studying for your driver's license on the Information Super Highway. Beep beep! --

"Open systems! Our systems! How well those who were there remember the pipe-festooned garret where Unix took form. The excitement of creation drew people to work there amidst the whine of the computer's cooling fans, even though almost the same computer access could be had from one's office or from home. Those raw quarters saw a procession of memorable events. The advent of software pipes precipitated a day-long orgy of one-liners...as people reveled in the power of functional composition in the large, which is even today unavailable to users of other systems. In another memorable event, the unarticulated notion of software tools, which had been bolstered by pipes, was finally brought home by the liberation of the pattern matching program grep from within the editor." (Ibid.)

Note that passing all tests is required for IEEE conformance, as well as 100% compatibility with Intel's coprocessors. Precision control forces the results of the FADD, FSUB, FMUL, FDIV, and FSQRT instruction to be rounded to the specified precision (single, double, double extended). This feature is provided to obtain compatibility with certain programming languages [17]. By specifying lower precision, one effectively nullifies the advantages of extended precision intermediate results.

While the 80x87 coprocessors perform all internal calculations in double extended precision and therefore have about the same performance for single and double-precision calculations, the Weitek features explicit single and double-precision operations. For applications that require only single- precision operations, the Weitek can therefore provide very high performance, as single-precision operations are about twice as fast as their double- precision counterparts. Also, since the Weitek Abacus has more registers than the 80x87 coprocessors (31 versus 8), values can be kept in registers more often and have to be loaded from memory less frequently. This also leads to performance gains.

There exist both old and new versions of Whetstone. Note that results from the two versions can differ by as much as 20% for the same test configuration. For this test, the new version in Pascal from [3] was used. It was compiled with Turbo Pascal 6.0 and my own library (see above) with all 'optimizations' on. All computations are performed using the DOUBLE type.

Summarizing the relationship between Bell Labs and the academic community in developing UNIX, Comer concludes:

Thus every time that a file is accessed, a cache will keep a copy of that file in memory set aside especially for that purpose. Since this special memory is limited, the cache has to have an algorithm to decide which parts of the cache to clear out to make room for new sectors. All the caches under discussion use the algorithm of discarding those parts of the cache which were least recently accessed; that is, not the ones that were first read the longest ago but rather than ones which were needed longest ago. Whenever DOS calls for a sector from disk, the cache program intercepts the call to check if the requested material is in the cache memory. If it is, the copy in memory is used and a disk access is saved. A cache can avoid anywhere from one-third to two-thirds of your disk accesses. To allow a large cache, it is natural to put the data part of the cache (that is, the copies of the sectors which were read rather than code that controls this data) in extended or expanded memory.

Table 2 shows the results of time tests. The tests are intended to be "real world" tests. Tests 1-4 are tests of cache read functions. Test 1 is the time to sort a 140K database that I had just sorted a different way. This demonstrates the savings you would get from repeated access to a database. Test 2 is the time to spell check a 40K document through the first pass which checks for possible misspellings. Test 3 is the time it took to convert a 500K database from one version of a database I had to another. Test 4 is the time to compile, link and EXE2BIN a 100K file which I had just treated by MASM, LINK and EXE2BIN on a hard disk and edited. This is typical of a situation where you may get a compiler error, correct the source file, and then recompile.

I am in the process of working on the current draft and I would appreciate any comments, suggestions, additional information, etc. regarding the early days of unix development and the work to develop computer science that this early work on unix represented.

Some 386 boards allow the coprocessor to be clocked differently than the CPU. This is called "asynchronous operation" and allows you, for example, to run the coprocessor at 33 MHz while the CPU runs at 40 MHz. Of the currently available math coprocessors, only the Intel 80387 and 387DX support asynchronous operation. The 387-compatible "clones" from Cyrix, C&T, IIT and ULSI always run at the full speed of the CPU, even if you have set up your motherboard for asynchronous operation.

ULSI coprocessors come with a lifetime warranty. ULSI Systems, Inc., will replace the coprocessor up to three times free of charge should it ever fail to function properly.

UNIX was attractive to the academic Computer Science community for several reasons. John Stoneback, describing these reasons, writes:

If you don't purchase and use one of these stand alone caching programs, you should at least be sure to make use of the free cache that comes with DOS. The cache size is set in units of 512 bytes called buffers. The default number, which DOS uses if you don't specify otherwise, is two for 8088 machines and three for 80826 based machines; both are woefully inadequate. To increase the number of buffers you must include a line

In our discussion of caching, various references will be made to the different kinds of memory that are available to microcomputer users. These include:

$$ Franke387 is a commercial 387 emulator that is also available in a shareware version. For this test, shareware version V2.4 was used. Franke387 unlike many other emulators supports all 387 instructions. It is loaded as a device driver and uses INT 7 to trap coprocessor instructions.

To many people, the Usenet IS the net. In fact, it is often confused with the Internet. But it is a totally separate information system that makes use of the Internet. The Usenet consists of many computers world-wide and moves over 25 megabytes (million characters) a day across the Internet.

The application of UNIX to automating the operating systems at Bell also involved automating the monitoring, measurement, help for routing and ensuring quality of calls. That was a "tall order," writes Tony Culwick, "given the standards people have come to expect...but the fact remains that the fundamental integrity of the national telecommunications network depends on more than 1000 real-time, mini-computer-based systems that are built on a version of the UNIX operating system." (from "Reach out and Touch the Unix System," by Tony Cuilwik, "Unix Review," June 1985, p. 50. Cuilwik was the head of the Operations Systems Development Department at Bell Laborators and then director of AT&T Information Systems Laboratories in Columbus, Ohio.)

Describing how research UNIX helped make it possible for academic computer science departments to establish and develop research in computer science, he writes:

In addition to being able to quickly execute load/store operations on floating-point numbers, the 80x87 coprocessors can directly perform all the basic arithmetic operation on them. Besides "knowing" how to add, subtract, multiply and divide floating-point numbers, they can also operate on them to perform comparisons, square roots, transcendental functions (such as logarithms and sine/cosine/tangent), and compute their absolute value and remainder.

It is a rare and wonderful event in the development of human society when a scientific and technological breakthrough is made which will certainly affect the future course of social contributions wer substantial, for example, those from the development and which becomes known when its midwives are still alive to tell us about it. UNIX, the product of researcher at Bell Labs, the then regulated AT&T system, and academic computer science, and a valuable invention for computer science, for computer education and for the education of the next generation of computer scientists and engineers, is such an event.

On Test #1 which is the most typical application of a cache, the cache programs all showed the same rather substantial gain. While there is a some spread on the other figures, the read tests really don't distinguish between the different caches. On writing, I'd give the nod to Super PC-Kwik and note that none of the tests adequately check for caching writes. The lack of this feature in Emmcache made me lean towards Super PC-Kwik. While Super PC-Kwik stands out as special in a positive way on writes, it also stands out negatively on diskette copies.

This coprocessor is basically a special version of the Cyrix 83D87, introduced in 1990. In addition to the normal 387 operating mode, in which coprocessor-CPU communication is handled through reserved IO ports, it also offers a memory-mapped mode of operation similar to the operation principle of the Weitek Abacus. Like the Weitek chip, the EMC87 occupies a block of memory starting at physical address C0000000h (the Abacus occupies a memory block of 64 KB, while the EMC87 uses only 4 KB [77]). It can therefore only be accessed in the protected or virtual modes of the 386 CPU. DOS programs can access the EMC87 with the help of DOS extenders or memory managers like EMM386 which run in protected/virtual mode themselves. To implement the memory-mapped interface, the usual 80x87 architecture has been slightly expanded with three additional registers and eleven additional instructions that can only be used if the memory-mapped mode is enabled.

Unlike Intel's coprocessors, which use the CORDIC [18,19] algorithm to compute the transcendental functions, Cyrix uses polynomial and rational approximations to the functions. In the past the CORDIC method has been popular since it requires only shifts and adds, which made it relatively easy to implement a reasonably fast algorithm. Recently, the cost for the implementation of fast floating-point hardware multipliers has dropped significantly (due to the availability of VLSI), making the use of polynomial and rational approximations superior to CORDIC for the generation of transcendental functions [61]. The Cyrix 83D87 uses a fast array multiplier, making its transcendental functions faster than those of any other 387 compatible coprocessor. It also uses 75 bit for the mantissa in intermediate calculations (as opposed to 68 bits on other coprocessors), making its transcendental functions more accurate than those of any other coprocessor or FPU (see results below).

A second aspect of caches in extended memory is that access of extended memory involves features in the ROM BIOS that are not often used in the current generation of AT software. Thus, the operation may be improper on some AT clones. In fact, Vcache comes with a program to test the BIOS access of extended memory. If there is a problem, the clone maker must correct it. Given the advent of a DOS that will access extended memory, it is essential to get such problems rectified.

However, when Bell Labs pulled out of the Multics project they took the Multics precursor off their GE 645 computer and put up GECOS, a much less state of the art operating system. "If you were an old line Spanish American War type computer user like me," Vyssotsky admits, "GECOS was a perfectly satisfactory system for getting from here to there in a well-designed application. You knew what it was going to do." (Ibid., p. 60)

Many caches will "read ahead", that is, read in an entire track whenever any reading takes place. If your files are large and not fragmented, this can give you a real speed advantage but if not, your cache will fill up with unused material. On a hard disk with many isolated bad sectors, read ahead can actually slow down disk access because of phantom disk errors. Lightning, Super PC-Kwik, and Vcache have read ahead while the others do not. Super PC-Kwik has the advantage of having read ahead as an option that you can turn off. The makers of Polyboost maintain that since most hard disks have errors and fragmented files, their lack of read ahead is a gain over the competition, but I think it will depend very much on your individual setup. In my own case, for example, I have turned read ahead off when running on my main machine because of the isolated bad sectors on my hard disk.

FTP refers to both the File Transfer Protocol and the software that implements the protocol. FTP allows you to transfer files over the Internet in a very efficient manner -- FTP is the Internet's upload and download program. FTP allows you to transfer literally any type of information stored as file: text, graphics, movies, software, you name it.

Selecting an Internet service provider is easy as there are many from which to choose. The big commercial information service outfits like America Online, Compuserve, and Prodigy have pretty good setups but they don't provide WWW access which is really what you want -- make sure to ask for it. If they don't know about the WWW or don't offer it, look elsewhere. Trust me. You want WWW.

o Lotus/Intel/Microsoft Expanded Memory Specification (LIM EMS) and supporting memory boards (up to 8 megabytes) are paged in and out of conventional memory, thereby providing the user with additional memory for supported software.

Establishing a standard UNIX, according to Tague, was "a process of negotiation and compromise with the UNIX-using community -- not a unilateral decision." (Ibid.) His group and the people at the variety of Bell sites "often ended up arguing things out until everybody understood the issues and a suitable compromise was made," he relates. (Ibid.)

The 80287 coprocessor-CPU interface is totally different from the 8087 design. Since the 80286 implements memory protection via an MMU based on segmentation, it would have been much too expensive to duplicate the whole memory protection logic on the coprocessor, which an interface solution similar to the 8087 would have required. Instead, in an 80286/80287 system, the CPU fetches and stores all opcodes and operands for the coprocessor. Information is then passed through the CPU ports F8h-FFh. (As these ports are accessible under program control, care must be taken in user programs not to accidentally perform write operations to them, as this could corrupt data in the math coprocessor.)

Two approaches to interface an 80x87 emulator to programs are common. The first method makes use of the fact that all coprocessor instruction start with the same five bit pattern 11011. Thus the first byte of a coprocessor instruction will be in the range D8-DF hexadecimal. In addition, coprocessor instructions usually are preceded by a WAIT instruction (opcode 9Bh) which is one byte long (the reason for doing this has been described in the previous chapter dealing with the operating details of the 80x87). One common approach is to replace the WAIT instruction and the first byte of the coprocessor instruction with one out of eight interrupt instructions; the remaining bytes of the coprocessor instruction are left unchanged. Interrupts 34 to 3B hexadecimal are used for this emulation technique. (Note that the sequences 9B D8 ... 9B DF can be easily converted to the interrupt instructions CD 34 ... CD 3B by simple addition and subtraction of constants.) The compiler or assembler initially produces code that contains these appropriate interrupt calls instead of the coprocessor instructions. If a hardware coprocessor is detected at run-time, the emulator interrupts point to a short routine that converts the interrupts calls back to coprocessor instructions (yes, this is known as "self-modifying code"). If no coprocessor is found the interrupts point to the emulation package, which examines the byte(s) following the interrupt instruction to determine which floating-point operation to perform. This method is used by many compilers, including those from Microsoft and Borland. It works with every 80x86 CPU from the 8086/8088 on.

This chip was introduced in 1989, only shortly after the coprocessors from IIT. It has been found to be the fastest 387-compatible coprocessor in several benchmark comparisons [1,7,68,69]. It also came out as the fastest coprocessor in my own tests (see benchmark results below). Although the Cyrix 83D87 provides up to 50% more performance than the Intel 387DX in benchmarks comparisons, the speed advantage over other 387-compatible coprocessors in real applications is usually much smaller, because coprocessor instructions represent only a small part of the total application code. For example, in a test using the program 3D- Studio, the Cyrix 83D87 was 6% faster than the Intel 387DX [1].

It seems to me that these programs, as a group, are somewhat overpriced. They are subtle but not that complicated as can be seen by the fact that the main programs are typically about 5K. Indeed, in cost per byte, they may be the most expensive class of programs on the market.

With these programs, you cannot cache a network by having a cache on your work station although you can sometimes cache the network disks with a cache on the server. These are complex issues and before attempting to use caches on machines connected to LANs, you should be sure to speak with both the cache vendor and the network vendor.

Nobody "owns" the Internet. There are companies that help manage different parts of the networks that tie everything together, but there is no single governing body that controls what happens on the Internet. The networks within different countries are funded and managed locally according to local policies. Individuals are responsible for the information they author and make available publicly on the Internet. Via the Internet, hundreds of thousands of people around the world are making information available from their homes, schools, and workplaces.

Test 5 and 6 test the ability to speed up disk writing. Test 5 is a PC Magazine "write random sectors" test. This test writes the same data repeatedly to sectors which may be the same and so it is particularly sensitive to the trick that caches use of suppressing a rewrite of identical data to what was earlier written to disk. Test 6 is a patched version of test 5 which writes different data each time. It was supplied to me by the publisher of Super PC-Kwik but I think it is a more significant test than the original test 5.

1. support for denormals in all precisions (single, double, extended) 2. support for the four IEEE rounding modes (up, down, nearest, chop) 3. support for precision control

One point to notice in the loading of the verb and word arrays, we don't do a FOR-NEXT loop - rather we go until we find "<<END>>". This allows us to edit the word lists without having to count the number of words in them and change the length of the loop. The only thing that we need to watch is that the array is large enough to handle the lists - in our case we can have 150 words in the verb array and 250 words in the other array with no problem, and with the memory that is basically standard in most machines today a small array like that is NO PROBLEM (after all, I write these things on a PC JR with 128K). One other thing to note is that we have changed the 'name' of the WORDS to TYPE, not really a large point but a confusing one if you don't catch it right away.

Speed of various coprocessor instructions, measured in clock cycles, as captured by my program 87TIMES. Error is +/- one clock cycle, except for the Intel 80287. Times for the 80287 were determined on a system with a 20 MHz 80386 and a 5 MHz Intel 80287. Therefore, times may differ from a genuine 80286/287 system, especially for those instructions that access an operand in memory. Since the times are stated as the number of coprocessor clock cycles used, the faster 386 which can execute four clock cycles where the 80287 executes one clock cycle may decrease memory access times as seen by the coprocessor.

Because the instruction sets of all 80x86 CPUs directly support only integers and calculations upon integers, floating-point numbers and operations on them must be programmed indirectly by using series of CPU integer instructions. This means that computations when floating-point numbers are used are far slower than normal, integer calculations. And this is where the 80x87 coprocessors come in: adding an 80x87 to an 80x86-based system augments the CPU architecture with eight floating-point registers, five additional data types and over 70 additional instructions, all designed to deal directly with floating-point numbers as a basic data type. This removes the 'penalty' for floating-point computations, and greatly increases overall system performance for applications which depend heavily on these calculations.

According to the Intel 387DX User's Guide, there are more than 2100 commercial programs that can make use of a 387-compatible coprocessor. Every program that uses floating-point arithmetic somewhere and contains the instructions to support an 80x87 or Weitek chip can gain speed by installing one. However, the speedup will vary from program to program (and even within the same program) depending on how computation-intensive the program or operation within the program is. Typical applications that benefit from the use of a math coprocessor are:

Contributors to rec.skydiving range from whuffos to Pat Works. The discussions can get pretty heated and sometimes long, but everyone has fun. Rec.skydiving is probably the most widely available electronic skydiving forum on the planet.

Different operations sites had taken on to create computer software to meet similar needs, such as print spooling, mail, help, etc. Tague's group's assignment was to gather the software and to determine what the standard should be and send the standard back out to the sites. Tague credits the technical strength of UNIX for making software standardization possible. UNIX "made it easy," he explains, "to get the right stuff in without upsetting the whole world."

The 83D87 (and its successor, the 387+) are the 387 'clones' with the highest degree of compatibility to the Intel 387DX. A few minor software and hardware incompatibilities have been documented by Cyrix [12]. The software differences are caused by some bugs present in the 387DX that Cyrix fixed in the 83D87. Unlike the Intel 387DX, the 83D87 (and all other 387-compatible chips as well) does not support asynchronous operation of CPU and coprocessor. There were also problems in the past with the CPU-coprocessor communications, causing the 83D87 to occasionally hang on some machines. The reason behind this was that Cyrix shaved off a wait state in the communication protocol, which caused a communications breakdown between the CPU and the 83D87 for some systems running at 25 MHz or faster. (One notable example of this behavior was the Intel 302 board.) Also there were problems with boards based on early revisions of the OPTI chipset. These problem are only rarely encountered with the current generation of 386 motherboards, and it is possible that it has been entirely eliminated in the 387+, the successor to the 83D87.

The initial version of this test data base for the proposed IEEE 754 binary floating-point standard (draft 8.0) was developed for Zilog, Inc. and was donated to the floating-point working group for dissemination. Errors in or additions to the distributed data base should be reported to the agency of distribution, with copies to Zilog, Inc., 1315 Dell Avenue, Campbell, CA, 95008.

At this point the parser just starts to examine the first command and to cut it into the individual words that make it up. In our example command at this point we would have set EXTRA, assigned "SOUTH" TO A1$, and would have split the first command into four individual words. The parser, as with all of the others that I am aware of, assigns the FIRST word to the verb and lets the others be as they may with the noun usually being the last word in the command.

The size of the emulator used by TP 6.0 is about 9.5 KB, while EM87 occupies about 15.8 KB as a TSR, and Franke387 uses about 13.4 KB as a device driver. Note that Franke387 and especially EM87 model a real coprocessor much more closely than Turbo Pascal's emulator does. In particular, EM87 supports denormal numbers, precision control, and rounding control. The emulator in TP 6.0 does not implement these features. The version of Franke387 tested (V2.4) supports denormals in single and double-precision, but not double extended precision, and it supports precision control, but not rounding control. The recently introduced shareware program Q387 only runs on 386, 386SX, 486SX and compatible processors. The program loads completely into extended memory and uses about 330 KB. To enable INT 7 trapping to a service routine in extended memory it needs to run with a memory manager (e.g. EMM386, QEMM, or 386MAX). The huge size of the program stems from the fact that it was solely optimized for speed, assuming that extended memory is a cheap resource. Presumably it uses large tables to speed computations. Intel's E80287 program is supposed to be an 100% exact emulation of the 80287 coprocessor [44]. Note that the more closely a real coprocessor is modelled by the emulator, the slower the emulator runs and the larger the code for the emulator gets.

Like most things in life, floating-point arithmetic has been standardized. The relevant standard (to which I will refer quite often in this document) is the "IEEE-754 Standard for Binary Floating-Point Arithmetic" [10,11]. The standard specifies numeric formats, value sets and how the basic arithmetic (+,-,*,/,sqrt, remainder) has to work. All the coprocessors covered in this document claim full or at least partial compliance with the IEEE-754 standard.

Disk caches are based on the idea that you are likely to want to access a file that you accessed recently. This is not only true for obvious data files like a database which you might search several times in a row, but also for program overlays and for the files that DOS often consults to locate other files: the FAT and the various directories, especially the root directory.

This is the fifth version of this document (dated 01-13-93) and I'd like to thank those who have helped improving it by commenting on the previous versions:

Once you have found the correct orientation, place the chip over the socket and make sure all pins are correctly aligned with their respective holes. Press firmly and evenly on the chip -- you may have to press hard to seat the coprocessor all the way. Again, make sure your motherboard does not bend more than slightly under the insertion pressure. For 8087, 287, and 387 coprocessors it is normal that the coprocessor does not go all the way in; about one millimeter (1/25 inch) of space is usually left between the socket and the bottom of the coprocessor chip. (This allows the insertion of a extraction device should it become necessary to remove the chip. Note that the construction of the 387SX's PLCC socket makes it next-to-impossible to remove the coprocessor once fully inserted, as the top of the chip is level with the socket's 'walls'.)

On the Evolution of Unix and the Automation of Telephone Support Operations (i.e. of Computer Automation) by Ronda Hauben

If your word processor fouls up a file write, all you are likely to lose is the file you wanted to save. Typically, the files in your cache include the FATs and root directories of your disks. If these go bad, you are likely to have real problems getting to any of the data on your entire disk. There are various tools which can help you recover from such a disaster, but they may not always work. This means that caches have an inherent danger to them. Of course, since DOS is also writing these files all the time, you could make the argument that caches are no more dangerous than DOS; perhaps even less so, since DOS keeps dirty buffers.

To get a file via FTP, you need to know the name of the file and where it is. Many FTP sites offer anonymous service which means anyone can get to the files stored on the site.

This chip is the second-generation successor to the Cyrix 83D87. (The name "387+" is only used for European distribution; in other parts of the world, it goes by the original 83D87 designation.) According to a source within Cyrix [73], the 387+ was designed to make a smaller (and thus cheaper to manufacture) coprocessor chip that could also be pushed to higher frequencies than the original chip: the 387+ is available in versions of up to 40 MHz, whereas the original 83D87 could go no faster than 33 MHz.

In trying to teach his students the essentials of a good operating system, John Lions describes how he prepared a booklet containing the source files for a version of Edition 6 of research UNIX in 1976 and the following year completed a set of explanatory notes to introduce students to the code. "Writing these," he recounts, "was a real learning exercise for me. By slowly and methodically surveying the whole kernel, I came to understand things that others had overlooked."

For safety's sake, you would not want these programs to delay writing to disk material that DOS wants to write to disk; this is called keeping dirty buffers and none of these programs keep dirty buffers. However, as I'll explain, DOS does some of its own disk caching and it does keep dirty buffers which can produce problems.

This math coprocessor was the predecessor of the Weitek Abacus 3167. It was actually a small printed circuit board with three chips mounted on it. In contrast to the Weitek 3167, the 1167 did not have a square root instruction; instead, the square root function was computed by means of a subroutine in the Weitek transcendental function library. However, the 1167 did have a mode in which it supported denormal numbers. (The Weitek 3167 and 4167 only implement the 'fast' mode, in which denormals are not supported.) Overall performance of the 1167 is slightly less than that of the Weitek 3167.

Not only did they need a good programming environment, but Mohr emphasized that the Bell System applications required, "Operations Systems, not Operating Systems. With the number of systems under consideration, the possiblity of being tied to a single vendor, or having each site tied to a different vendor, induced a kind of paranoia. There just had to be another way." (Mohr, p.22 )

Note that earlier Intel coprocessors (the 8087 and the 80287) comply with a draft version of the standard that differs from the final version. These chips were developed before IEEE-754 was finally accepted in 1985. As with the 80387, the basic arithmetic in the 8087 and the 80287 is 'exact' in the sense that the computed result is always the machine number closest to the real result. However, there are some differences regarding certain operands like infinities, and some operations like the remainder are defined differently than in the final version of the standard.

The parser starts off by checking to see if the command that was input is smaller then three letters long or is a "G", if so a lot of the work can be eliminated. Other checks that are performed at this time let the computer know if the command that has been entered is multiple or not, and in the case of our example it is. This is signified by the use of "THEN" or by using a period, with this information the computer cuts off the rest of the command line and assigns it to a holding string (A1$) and sets EXTRA to 1. From this point the parser checks to see if we are using "G" or"AGAIN" which tells it to repeat the last command, i.e. the command "GO NORTH. G THEN GET THE CAT. S THEN NW" is perfectly legal and will be fully complied with - if you haven't made a mistake (if there is no cat then you won't get it, but you will end up where you told the computer to put you - so it is important to know what you really want to do before using the multiple command feature).

A neat trick to enhance the processing power of the 8087 for computations that use only the basic arithmetic operations (+,-,*,/) and do not require high precision is to set the precision control to single- precision. This gives one a performance increase of up to 20%. For details about programming the precision control, see program PCtrl in appendix A.

If your university or company has Internet access, ask your computer coordinator about using the World Wide Web (WWW). Once you get access to the Web, everything else (FTP, Usenet news) will likely follow. Besides, if you're new to the Internet you'll want to start with the WWW anyway.

; IIT_MUL_4x4 multiplicates a four-by-four matrix by an array of four ; dimensional vectors. This operation is needed for 3D transformations ; in graphics data processing. There are arrays for each component of ; a vector. Thus there is an array containing all the x components, ; another containing all the y components and so on. Each component is ; an 8 byte IEEE floating-point number. Two indices into the array of ; vectors are given. The first is the index of the vector that will be ; processed first, the second is the index of the vector processed ; last. This subroutine uses the special instructions only available ; on IIT coprocessors to provide fast matrix multiply capabilities. ; So make sure to use it only on IIT coprocessors.

This is the Usenet, a global meeting place, where people gather to discuss the day's events, keep up with computer trends, or talk about whatever's on their mind. Jumping (pun intended) into a Usenet discussion can be a liberating experience. Nobody knows what you look or sound like, how old you are, or what your background is. You're judged solely on your words, your ability to make a point.

In the absence of a coprocessor, floating-point calculations are often performed by a software package that simulates its operations. Such a program is called a coprocessor emulator. Simulating the coprocessor has the advantage for application programs that identical code can be generated for use with either the coprocessor and the emulator, so that it's possible to write programs that run on any system without regard to whether a coprocessor is present or not. Whether the program will use an actual coprocessor or software emulating it can easily be determined at run-time by detecting the presence or absence of the coprocessor chip.

In the process of using UNIX within Bell Labs, bugs would be discovered and reported to the programmers, or new applications would be created by the departments using the programs for their own tasks. The research labs would need to provide maintenance and updating of software as well as getting the bug reports to the programmer and sending out fixes.

The World Wide Web (WWW) is a distributed information system that, among other things, helps users find information on the Internet. The Web is actually a set of documents which refer to each other by "links" -- words or phrases in a document that are associated with a unique network information resource or some other Web document.

Since IEEETEST is written in Turbo Pascal, it was recompiled with the $E+ switch to enable use of the coprocessor emulator built into the TP 6.0 library. Using the emulator, IEEETEST aborted in the following tests with a division by zero error: 'Comparison', 'Division', 'Next After'. These tests were removed from the suite and the remaining tests were performed. The public domain emulator EM87 could be tested, but hung in the last test which checks the implementation of the remainder operation. This problem occurred because EM87 incorrectly identifies itself as an 387 type coprocessor when run on an 80386. This causes the 387 specific FUCOM instruction to be used in the 'Comparison' and 'Next After' tests and the FPREM1 instruction to be used in the 'Remainder' test. Apparently EM87 is not able to emulate these instructions and therefore crashes upon trying to execute them. It is interesting to note how the error profile of EM87 matches exactly that of the Intel 80287, so it can be assumed that EM87 is a very good emulation of the 80287 when run on the 80286. The Franke387 V2.4 emulator hangs in the following test performed by IEEETEST: 'Division', 'Multiplication', 'Scalb', 'Remainder'. The cause for these failures is unknown.

Detailing the reasons for the decision, Vyssotsky responds, "It turned out that from our point of view the Multics effort simply went awry. In the first place, we were naive about how hard it was going to be to create an operating system as ambitious as Multics. It was the familiar second system syndrome. You put in everything you wished you'd had in the other one."(Vyssotsky, pg. 59) Also he details how GE, MIT, and AT&T each had different goals for the project, which made it difficult for them to work together. While GE wanted to develop Multics to "strengthen its product line," MIT wanted Multics "to advance the state of art" of computing, and Bell Labs' purpose was to have a good environment for our people to work in." (Ibid.) Given these different objectives, Vyssotsky explains, "It turned out that under the stress of slipping schedules and the increasing realization that we had difficulty agreeing on a common course of action, we ended up simply pulling out of Multics. We said, `OK, it's too wet to plow. We aren't going to get from here to there'."(Ibid.)

"Constant discussions honed the system....Should tools usually accept output file names? How to handle demountable media? How to manipulate addresses in a higher level language? How to minimize the information deducible from a rejected login? Peer pressure and simple pride in workmanship caused gobs of code to be rewritten or discarded as better or more basic ideas emerged. Professional rivalry and protection of turf were practically unknown: so many good things were happening that nobody needed to be proprietary about innovations." [from M.D. McIlroy, "Unix on My Mind," Proc. Virginia Computer Users Conference, vol 21, Sept. 1991, Blacksburg, p. 1-6.]

Abstract: 1994 is the 25th anniversary of the invention of the UNIX kernel at Bell Labs. The following article is a chapter in a longer paper documenting some of the events that have contributed to the development of a Global Computer Network in the past 25 years. This article describes how the need to automate telephone support operations in the U.S. in the late 1960s and the early 1970s nourished the birth and developement of the UNIX operating system and how academic computer science contributed to and gained from the development of UNIX. This article is intended as a contribution to a 25th anniversary commemoration of the significance of the UNIX breakthrough and the lessons that can be learned for making the next step forward.

Another compatibility issue that has been discussed on Usenet is the behavior of the math coprocessors under protected-mode operating systems. I have seen postings claiming that coprocessors from ULSI, IIT, and Cyrix locked up the machine when a protected mode operating system (several UNIX derivatives were also mentioned) was run on them. However, there have also been reports that several 486-based systems also have this problem, while others do not. Therefore, I think most of these problems are caused by poor motherboard design, especially wrong handling of error interrupts coming from the coprocessor. There could also be bugs in the exception handlers of the operating system.

URLs can specify all kinds of information on the Internet. For example, the following URLs specify the skydiving FTP and Gopher sites as well as the Usenet newsgroup rec.skydiving:

One of the reasons emulators are so slow is that they are often designed to run with every CPU from the 8086/8088 on upwards. This is the case with the emulators built into the compiler libraries of the Turbo Pascal 6.0 (also used by Turbo C/C++) and Microsoft C 6.0 compiler (probably also used in other Microsoft products) and is also true for the EM87 emulator in the public domain. By using code that can run on a 8086/8088, these emulators forego the speed advantage offered by the additional instructions and architectural enhancements (such as 32-bit registers) of the more advanced Intel 80x86 processors. A notable exception to this is the Franke387 emulator, a commercial emulator that is also sold as shareware. It uses 386- specific 32-bit code and only runs on 386/386SX/486SX computers.

Here is a special report I think will be of interest to telecom readers on the forthcoming 25th anniversary of the invention of the Unix kernel at Bell Labs in 1969.

But memory access, even by slow memory chips, is much faster than even speedy hard disks; diskettes are even slower. While disk transfer rates are slower than RAM exchanges, they are speedy compared to output through parallel or serial ports, where transfer rates are measured in 100's of bytes per second. (1200 baud, for example, means roughly 120 characters per second.) And your console, the name for the combined keyboard/monitor I/O device must interface the computer's slowest component -- you; its speeds are often the slowest of all.

The 387 clone manufacturers all claim 100% compatibility with Intel's 80387, so one would reasonably expect the same accuracy from their chips as from Intel's. For example, on the packaging of the IIT 3C87 it states that "...the requirements of ANSI/IEEE standards are fulfilled and exceeded". Cyrix states that their 83D87 complies fully with the IEEE-754 standard [12], and in fact delivers with their coprocessors diagnostic software that includes the program IEEETEST. This program is based on the IEEE test vectors from the PhD thesis of Dr. Jerome T. Coonen [9]. A test using the IEEE test vectors has also been included into the RUNDIAG program on the Intel RapidCAD diagnostic disk. Rather than performing random tests, the test vectors check specific cases that may be hard to get right. Each test vector specifies the operation to be performed, the operands, precision and rounding mode to be used, and the result (including flags set) to be expected according to the IEEE-754 standard.

Table 1 shows memory usage of the cache; it lists the amount of conventional memory used by the control part of the software exclusive of the memory taken by the cache. If you put the cache in conventional memory, the amount in this table will be overwhelmed by the amount of memory taken by the cache itself but, if you place the cache in EMS or extended memory, this figure will be quite important. For some of the conventional memory caches, you pick only the total size of cache plus controlling code. For these, the amount of memory in the control part cannot be determined; these are indicated in the Table with an *. All numbers are in kilobytes except for the first row. For those that allow you to decrease the number of DOS buffers, the second row can show a rather significant savings. The figures for diskette cache give the amount needed to cache two diskette drives; for several of the programs, diskette caching is automatic and this amount is then listed as zero. Polyboost suggests that you won't need to cache diskette drives if you have a hard drive; depending on your mode of operation, that may be true.

Just as Operating Systems people in the Bell system had come to recognize the need for portability in a computer operating system, Ritchie and Thompson and the other programming researchers at Bell Labs had created the computer language C and rewritten the majority of the UNIX kernel in C and thus had made the important breakthrough in creating a computer operating system that was not machine dependent. Describing their breakthrough with UNIX, Thompson and Ritchie presented their first paper on UNIX at the Symposium on Operating Systems Principles, IBM Thomas J. Watson Research Center, Yorktown Heights, New York, October 15-17, 1973,(reference from UNIX(tm) Time-Sharing System: Unix Programmers Manual, 7th edition, vol 2, Murray Hill, f/n pg 20). See also Ritchie's account of the creation of C by early 1973 in "The Development of the C Language," ACM, presented at Second History of Programming Languages conference, Cambridge, Mass, April 1993, p. 1) Describing this important achievement by Bell Labs researchers, Mohr writes, "the integral portability of the system developed by Research proved adequate to make UNIX portable over a wide range of hardware."

Tague explains that his role in planning for the transition meant that he tried to warn those involved that they would need a good software environment to do the development of the software needed to use the mini computers for these new roles.

Some new instructions were introduced with the 80387, most notably the FSIN and FCOS operations. The argument range for some transcendental function has also been extended [17]. Note that the IEEE-754 standard says nothing about the quality of the implementation of transcendental functions like sin, cos, tan, arctan, log. Intel uses a modified CORDIC [18,19] technique to compute the transcendental functions; Intel claims that maximum error in the 8087, 80287, and 80387 for all transcendental functions does not exceed two bits in the mantissa of the double extended format, which features 64 mantissa bits for an overall accuracy of approximately 19 decimal places [22,23]. This claim has been independently verified by a competing vendor [13]. This means that at least 62 of the 64 mantissa bits returned as a result by one of the transcendental function instructions are guaranteed to be correct.

The ULSI 83C87 fails to be compatible with the IEEE-754 in that is does not implement the "precision control" feature. While all the internal operations of 80x87 coprocessors are usually performed with the maximum precision available (double-extended precision with 64 mantissa bits), the 80x87 architecture also offer the possibility to force lower precision to be used for the basic arithmetic functions (add, subtract, multiply, divide, and square root). This feature is required by IEEE-754 for all coprocessors that can not store results *directly* to a single or double-precision location. Since 80x87 coprocessors lack this storage capability, they all implement precision control to provide correctly rounded single- and double-precision results according to the floating- point standard - except the ULSI chips. For programs that make use of precision control (e.g., Interactive UNIX), correct implementation of the feature may be essential for correct arithmetic results.

PEAKFLOP is the kernel of a fractal computation. It consists mainly of a tight loop written in assembly code and fine-tuned to give maximum performance. The whole program fits nicely into even a very small CPU cache. All variables are held in the CPU's and coprocessor's registers, so the only memory access is for opcode fetches. The main loop contains three multiplications and five additions/ subtractions; this ratio is fairly typical for other floating-point intensive programs as well. Due to the nature of this program, its MFLOPS rate is hardly to be exceeded by any program that calculates anything useful; thus the name PEAKFLOP. You will find the source code for PEAKFLOP in appendix B.

This coprocessor is designed for use in systems that contain an Intel 386SL as the CPU. The 386SL is directly derived from the 386SX. It is a static CHMOS IV design with very low power requirements that is intended to be used in notebook and laptop computers. It features an integrated cache controller, a programmable memory controller, and hardware support for expanded memory according to the LIM EMS 4.0 standard. The 387SL, introduced in early 1992, has been designed to accompany the 386SL in machines with low power consumption and substitute the 387SX for this purpose. It features advanced power saving mechanisms. It is based on the 387DX core, rather than on the older and slower 80387 core (which is used by the 387SX).

The Cyrix 486DLC is currently the 386 'clone' with the highest integer performance. With the internal cache enabled, integer performance of the 486DLC can be up to 80% higher than that of an Intel 386DX at the same clock frequency, with the average speed gain for most applications being about 35%. Floating-point applications are typically accelerated by about 15%-30% when using a Cyrix 486DLC (with its cache enabled) instead of the Intel 386DX.

Also, he knew that there would be a need to develop a support system for those operating companies around the country that would begin to use UNIX: "We were starting to put these things in the operating companies all around the countryside," explains Tague, "and the prospects were that there were going to be several hundred minis over the next few years that were going to have to be maintained with all their software and hardware." (Ibid., pg. 24)

Besides its higher performance, the 486 FPU provides more accurate transcendental functions than the 387DX coprocessor, according to my tests (see below). To achieve better interrupt latency, FPU instructions with a long execution times have been made abortable if an interrupt occurs during their execution.

To reduce power consumption the 83D87 features advanced power saving features. Those portions of the coprocessor that are not needed are automatically shut down. If no coprocessor instructions are being executed, *all* parts except the bus interface unit are shut down [12]. Maximal power consumption of the Cyrix 83D87 at 33 MHz is 1900 mW, while typical power consumption at this clock frequency is 500 mW [15].

But for a research computer scientist like Ken Thompson, GECOS was inadequate. According to Vyssotsky, "It was nowhere near as satisfactory if you were trying to do things that were technically difficult and imperfectly defined, which is the main task of research."(Ibid.)

Explaining the importance of how unix was implemented organizationally within the Bell System, Vyssotsky comments, "There are a lot of organizations that do not work that way. I brought out that little hunk of history to point out that the spread and success of UNIX, first in the Bell organizations and then in the rest of the world, was due to the fact that it was used, modified, and tinkered up in a whole variety of organizations within Bell Laboratories ... the refinement of UNIX was not done as the result of some management initiative or council of vice presidents. It was the supervisors saying, "This thing is already better than our other options and flexible enough for us to make it a go." (Ibid. p. 64)

Note that for the Intel coprocessors, running programs in single vs. double- precision doesn't provide much of an performance advantage since all internal calculations are always done in extended precision. Using Weitek coprocessors, however, performance nearly doubles in single-precision mode. For double-precision calculations using only basic arithmetic, the Weitek Abacus can at most provide performance at twice the level of the respective Intel coprocessor (387/486) at the same clock speed.

If you don't have Internet access at work or school don't worry -- you can gain access from home. You will need some sort of computer and a modem and the faster the modem the better (9600 bps or more is best). A graphical environment like Microsoft Windows or the Macintosh is preferable.

In my tests, I found the Cyrix 387+ to be about five to 10 percent *slower* than the Cyrix 83D87. However, some instructions like the square root (FSQRT) now run at only half the speed at which they ran in the 83D87, and most transcendental functions show about a 40% drop in performance compared to their 83D87 averages (see performance results, below). However, I did find the transcendental functions on the 387+ to be a bit *more* accurate than those implemented in the 83D87. The new design uses a slower hardware multiplier that needs six clock cycles to multiply the floating-point mantissa of an internal precision number, while the multiplier in the 83D87 takes only 4 clocks to accomplish the same task. Since the transcendental functions in Cyrix math coprocessors are generated by polynomial and rational approximations, this slows them down significantly.

Using UUCP, the UNIX community was able to pioneer still another advance, Usenet News. "Though large institutions have been able to avail themselves of communications networks such as ARPANET, the UNIX community has made inexpensive electronic communication available to all of its members via Usenet," writes Stoneback, "A community that already had so much in common," he explains, "was strengthened and enhanced by the ability to move software easily among locations and to maintain a reasonable electronic mail system. The cost of this network has been borne at least in part by private industry, thus mitigating expenses for the users themselves. The Usenet network stands today as a clear sign that the UNIX community is solidly in place. It now includes numerous corporate members providing universities on the network with the added advantage of pooling academic researchers, industrial developers, industrial researchers and regular users. Combined with a functional, cheap electronic communication system, Usenet offers the academic community unique advantages." (Stoneback, p. 26)

The 3167 was introduced by Weitek in 1989 and provided the fastest floating-point performance possible on a 386 based system at that time. The 3167 is not a real coprocessor, strictly speaking, but rather a memory-mapped peripheral device. The architecture of the 3167 was optimized for speed wherever possible. Besides using the faster memory mapped interface to the CPU (the 80x87 uses IO-ports), it does not support many of the features of the 80x87 coprocessors, allowing all of the chip's resources to be concentrated on the fast execution of the basic arithmetic operations. (For a more detailed description of the Weitek 3167, see the first chapter of this document.)

Tague describes how UNIX had been functioning in the research environment and thus had demonstrated that it could be used as a beginning basis for this important job.

The eight registers in the 80x87 are organized in a stack-like manner which takes some time getting used to if one programs the coprocessor directly in assembly language. However, nowadays the compilers or interpreters for most high level languages (HLLs) can give a programmer easy access to the coprocessor's data types and use their instructions, so there is not much need to deal directly with the rather unusual architecture of the 80x87.

Which should you use? That depends on how you use your computer. If you only use a few programs without extensive data files, a RAM disk is probably better if you can make one large enough to hold what it needs to. In other circumstances, a cache may be preferable. If you have the RAM, there may be sense in using both: a RAM disk for your common programs and a cache to take up the slack. Most of the cache programs have built-in procedures to avoid caching programs from the RAM disk, allowing you to save valuable cache space for files from your physical disks.

If you are installing the Intel RapidCAD chipset in a 386 system, you will have to remove the 386 CPU first. Intel provides an easy-to-use chip extractor and a storage box for the 386 chip for this purpose. Just follow the instructions in the RapidCAD installation manual.

UUCP made such exchanges easier. It was included with the Version 7 UNIX, which was made available to the academic community outside of Bell Labs. UUCP made it possible for UNIX users to communicate with each other even when they were at spatially distant locations.

The use of UNIX as a basis for operating systems research has produced three highly desirable consequences. First, the availability of a common system allowed researchers to reproduce and verify each others' experiments. Such verification is the essence of science. Second, having a solid base of systems software made it possible for experimenters to build on the work of others and to tackle significant ideas without wasting time developing all the pieces from scratch. Such a basis is prerequisite to productive research. Third, the use of a single system as both a research vehicle and a conventional source of computing allowed researchers to move results from the laboratory to the production environment quickly. Such quick transition is mandatory of state-of-the-art computing." (Comer, p. 44)

The IIT 2C87 provides extra functions not available on any other 287 chip [38]. It has 24 user-accessible floating-point registers organized into three register banks. Additional instructions (FSBP0, FSBP1, FSBP2) allow switching from one bank to another. (Transfers between registers in different banks are not supported, however, so this feature by itself is of limited usefulness. Also, there seems to be only one status register (containing the stack top pointer), so it has to be manually loaded and stored when switching between banks with a different number of registers in use [40]). The register bank's main purpose is to aid the fourth additional instruction the 2C87 has (F4X4), which does a full multiply of a 4x4 matrix by a 4x1 vector, an operation common in 3D- graphics applications [39]. The built-in matrix multiply speeds this operation up by a factor of 6 to 8 when compared to a programmed solution according to the manufacturer [38]. Tests show the speed-up to be indeed in this range [40]. For the 3C87, I measured the execution time of F4X4 to be about 280 clock cycles; the execution time on the 2C87 should be somewhat larger - I estimate it to be around 310 clock cycles due to the higher CPU-NDP communication overhead in instruction execution in 286/287 systems (~45-50 clock cycles) compared with 386/387 systems (~16-20 clock cycles). As desirable as the F4X4 instruction may seem, however, there are very few applications that make use of it when an IIT coprocessor is detected at run time (among them Schroff Development's Silver Screen and Evolution Computing's Fast-CAD 3-D

The Intel Math Coprocessor Utilities Disk that accompanies the Intel 387DX coprocessor has a demonstration program that shows the speedup of certain application programs when run with the Intel coprocessor versus a system with no coprocessor:

During the same period that the search for an operating system to replace the promise of Multics had begun by Bell Labs computer programming researchers, the Bell System was faced with the problem of automating their telephone operations using minicomputers. Describing the problem facing the Bell System during this period, August Mohr, in an article in Unix Review, "The Genesis Story"(January 1985, p. 22), writes "Bell was starting to perceive the need for minicomputer support for its telephone operations." (Mohr was editor of /usr/group 's CommUNIXations newsletter.)

This IIT chip was introduced in 1989, about the same time as the Cyrix 83D87. Both coprocessors are faster than Intel's 387DX coprocessor. The IIT 3C87 also provides extra functions not available on any other 387 chip [38]. It has 24 user-accessible floating-point registers organized into three register banks. Three additional instructions (FSBP0, FSBP1, FSBP2) allow switching from one bank to another. (Transfers between registers in different banks are not supported, however, so this feature by itself is of limited usefulness. Also, there seems to be only one status register [containing the stack top pointer], so it has to be manually loaded and stored when switching between banks with a different number of registers in use [40]). The register bank's main purpose is to aid the fourth additional instruction the 3C87 has (F4X4), which does a full multiply of a 4x4 matrix by a 4x1 vector, an operation common in 3D-graphics applications [39]. The built-in matrix multiply speeds this operation up by a factor of 6 to 8 when compared to a programmed solution according to the manufacturer [38]. Tests show the speed-up to be indeed in this range [40]. I measured the F4X4 to execute in about 280 clock cycles, during which time it executes 16 multiplications and 12 additions. The built-in matrix multiply speeds up the matrix-by- vector multiply by a factor of 3 compared with a programmed solution according to IIT [39]. The results for my own TRNSFORM benchmark support this claim (see results below), showing a performance increase by a factor of about 2.5. This makes matrix multiplies on the IIT 3C87 nearly as fast as on an Intel 486 at the same clock frequency. As desirable as the F4X4 instruction may seem, however, there are very few applications that make use of it when an IIT coprocessor is detected at run time (among them Schroff Development's Silver Screen and Evolution Computing's Fast-CAD 3-D [25]).

Lions describes how he helped to develop a UNIX tool "pack" which was eventually combined with tools created at Bell Labs called huff and unhuff and distributed as a standard UNIX command. He and others from his college were invited to spend periods of time at Bell Labs to work with the unix researchers there. (See for example, pg. 57)

Be sure you are properly grounded before you remove the coprocessor from its antistatic box, as even a tiny jolt of static electricity can ruin the coprocessor. Make sure you do not touch the pins on the bottom of the chip.

[44] This is the original Intel coprocessor for the 80286, introduced in 1983. It uses the same internal execution unit as the 8087 and therefore has the same speed (actually, it is sometimes slower due to additional overhead in CPU-coprocessor communication). As with the 8087, it does not provide full compatibility with the IEEE-754 floating point standard released in 1985.

Meanwhile, academic UNIX users had to do their own software maintenance. Lions describes how a community of academic unix users grew up who were willing to help each other.

The Weitek Abacus 3167 and 4167 coprocessors are 'mostly compatible' with IEEE-754 [31,32,33]. They support the single-precision and double precision numeric formats described in the standard, as well as the four rounding modes required by it. However, due to Weitek's desire for extremely high-speed operation, some of the finer points of IEEE-754 have not been implemented. One of the most notable omissions is the missing support for denormal numbers; denormals are always flushed to zero on Weitek chips.

"Bell had already gained some field support experience switching machines and their software. Supporting a network of mini computers would be a significantly different problem." -- August Mohr, "The Genesis Story," Unix Review, Jan. 1985, p.24

The EM87 emulator could not be checked with TRANCK, since the multiple precision package in TRANCK would always return with an error message immediately. However, the Franke387 emulator could be tested.

In existing 386 systems, DMA transfers (e.g., by a SCSI controller or a soundcard) may cause the 486DLC's entire on-chip cache to be flushed, since no other means exist to enforce consistency between the cache contents and main memory. This reduces the performance of the 486DLC in these cases. The 486DLC on-chip cache does, however, allow specification of up to four non- cacheable regions, which is particularly useful if your system has memory mapped peripherals (e.g., a Weitek coprocessor).

"rec.skydiving" is the newsgroup for skydiving. Information in a newsgroup is stored as individual messages called articles. People from all over the world read and write these articles. A recent discussion (called a "thread") on rec.skydiving centered around ground speed vs. air speed during spotting, instigated by the letter to the editor in the December 1994 _Parachutist_. The articles ranged from mathematical discourses on the physics of airplanes and skydivers in freefall to summaries of personal experiences.

I cannot answer the questions about whether disk caches are really dangerous. I can report that I've met several users who are sure that problems they've had with FATs were caused by cache programs. This may well be true, although it is also true that if you have any problems with the logical structure of your disk and you have a cache, you are likely to blame the cache. During the testing of cache programs which went over six months, I lost the contents of one of my hard disks three times. Two seemed to be hardware problems solved in one case by a low level reformat and in the other by a disk replacement. But the third one involved a piece of software crashing the system; after rebooting, the root directory on the hard disk was chopped liver. I'm suspicious that the culprit was the cache I was using but maybe it was DOS' dirty buffers or the program that crashed in the first place. All I can say is that caching may be risky. You should be sure to back up often but especially so if you have a cache. In fact, unless you are willing to back up regularly, I recommend strongly against a cache. On the other hand, caches are rather useful. I'm still using a cache in spite of the problems that I had and some of those who are certain that they had cache related problems are still using them. And I've met people who feel that caches are among their most important utilities.

Note that a maximum relative error of 0.5 ULP for the Cyrix coprocessor does not mean that it returns the 'exact' result (machine number closest to infinitely precise result) all the time. Consider the case where the infinitely precise result of a transcendental function falls nearly halfway between two machine numbers. A relative error of 0.5 ULP can cause the result to be either of the numbers after rounding, depending on the direction of the error. But the 83D87 should deliver results that never differ from the 'exact' result by more than one ULP. Also note that the claim of relative error being below 0.5 ULPs is slightly exaggerated; 0.6 ULPs would be a more realistic error limit. Imagine that the infinitely precise result for some argument to a transcendental was xxx..xxx1001... (where the xxx...xxx represent the first 64 bits of the result), but that the coprocessor computes the result as xxx..xxx0111 and then round this down to xxx..xxx0000. Then the relative error is (1001b-0b)/1000b = 0.5625 ULPs.

Not only did research UNIX serve the academic community, but the contributions of the academic community were incorporated into research UNIX. An example, is the work by Babaoglu and Porker at UC Berkeley of designing a virtual memory version of UNIX for the VAX computer which was later optimized by Bill Joy and incorporated into a release of UNIX. (Ibid.)

For example, the skydiving FTP site is located on the machine skydive.eng.ufl.edu. The files are located in the skydive directory on the site. So to get, say, the world DZ price list, you'd FTP to skydive.eng.ufl.edu, log in as the user "anonymous" (entering your email address as the password as a courtesy to the site maintainers), go to "skydive" directory, and get the file "Prices."

By 1964, however, the Labs was adopting third generation computer equipment and had to decide whether they would build their own operating system or go with one that was built outside the Labs. Vyssotsky recounts the process of deliberation at the time, "Through a rather murky process of internal deliberation we decided to join forces with General Electric and MIT to create Multics," he explains. The Labs planned to use the Multics operating system "as a mainstay for Bell Laboratories internal service computing in precisely the way that we had used the BESYS operating system." (Ibid., p. 59)

This ability to present his students with a real example of an operating system kernel was a breakthrough. Lions writes:

The divide/square root logic has also been changed from the 83D87 design. The original design used an algorithm that could generate both the quotient and square root, so the execution times for these instructions were nearly identical. The algorithm chosen for the division in the 387+ doesn't allow the square root to be taken so easily, so it takes nearly twice as long.

TRNSFORM multiplies an array of 8191 vectors with a 3D-transformation matrix (a 4x4 matrix). Each vector consists of four double-precision values. Multiplying vectors with a matrix is a typical operation in the manipulation (e.g. rotation) of 3D objects which are made up from many vectors describing the object. This benchmark stresses addition and multiplication as well as memory access. For each vector, 16 multiplications and 12 additions are used, and about 256 KB of data is accessed during the benchmark run.

4) Match the coprocessor's orientation with the orientation of the socket. Correct orientation of the coprocessor is absolutely essential, because if you insert it the wrong way it may be damaged.

In 8086/8088 systems with 8087 coprocessors, both chips look at every opcode coming in from the bus. To do this, both chips have the same BIU (bus interface unit) and the 8086 BIU sends the status signals of its prefetch queue to the 8087 BIU. This insures that both processors always decode the same instructions in parallel. Since all coprocessor instruction start with the bit pattern 11011, it is easy for the 8087 to ignore all other instructions. Likewise the CPU ignores all coprocessor instructions, unless they access memory. In this case, the CPU computes the address of the LSB (least significant byte) of the memory operand and does a dummy read. The 8087 then takes the data from the data bus. If more than one memory access is needed to load an memory operand, the 8087 requests the bus from the CPU, generates the consecutive addresses of the operand's bytes and fetches them from the data bus. After completing the operation, the 8087 hands bus control back to the CPU. Since 8087 and CPU are hooked up to the same synchronous bus, they must run at the same speed. This means that with the 8087, only synchronous operation of CPU and coprocessor is possible.

The same synchronization is used before the CPU accesses data that was written by the coprocessor. A WAIT instruction after any coprocessor instruction that writes to memory causes the CPU to stop until the coprocessor has completed transfer of the data to memory, after which the CPU can safely access it.

The UNIX kernel is an I/O multiplexer more than a complete operating system. This is as it should be. Because of this outlook, many features are found in most other operating systems that are missing from the UNIX kernel. For example, the UNIX kernel does not support file access methods, file disposition, file formats, file maximum sizes, spooling, command language, logical records, physical records, assignment of logical file names, logical file names, more than one character set, an operator's console, an operator, log-in, or log-out. Many of these things are symptoms rather than features. Many of these things are implemented in user software using the kernel as a tool. A good example of this is the command language. Maintenance of such code is as easy as maintaining user code. The idea of implementing "system" code and general user primitives comes directly from MULTICS." (Ibid., p. 1945-6)

As work continued on the Bell Labs operating system, the researchers developed a set of principles to guide their work. Among these principles were:

Describing the functions that UNIX makes possible, he writes, "Among the varied and wide-ranging functions these systems perform are network performance measurement, automated network testing, circuit order planning, circuit order record-keeping, automated trouble detection, automated or directed trouble repair, service quality assurance, quality control, inventory control, customer record-keeping, and customer billing -- as well as any number of other operational and administrative functions. These functions all require," Cuilwik explains, "the ability to present data to users in real-time." (Ibid.)

Describing the considerations by Bell Labs at this time, Vyssotky explains, (from Vyssotsky, pg. 64)" In 1976, there were those three versions of UNIX. The Change Control Process on all three of those versions was such that, at any moment in time, the people who were programming could tell what changes had gotten in and what changes were scheduled to go in. However, it was still a little hard for the users to tell what they were getting. It wasn't until 1978 that we had anything that I would consider to be a reasonable configuration management process of UNIX. That was the point at which we finally realized we had something which, like it or not, was a major product. So we said, `Given that it is a major product, there can be no horsing around.' We could no longer regard it as something in the underbrush. We had to regularize our arrangements. We set up a process for configuration management and we focused the thing in the direction of a coherent system." (Vyssorsky, pg. 64-68)

While support for 80x87 coprocessors is very common in application programs, the Weitek Abacus coprocessors do not enjoy such widespread support. Due to their higher price, only a few high-end PCs have been equipped with Weitek coprocessors. Some machines, such as IBM's PS/2 series, do not even have sockets to accommodate them. Therefore, most of the programs that support these coprocessors are also high-end products, like AutoCAD and Versacad-386.

"This meant," he elaborates, "that if I was responsible for keeping the Superbowl broadcast on the air between New Orleans and New York, I could -- with a single console -- view all the connections on that link and have access to all of the information automatically being collected about it. If something broke, I could immediately recognize that and orchestrate the process of getting it repaired. The repair itself would ultimately be left to a person working in much the same way as before." (Ibid.)

The 4167 is a memory-mapped coprocessor that has the same architecture as the 3167; it is designed to provide 486-based systems with the highest floating-point performance available. It executes coprocessor instructions at three to four times the speed of the Weitek 3167. Although it is up to 80% faster than the Intel 486 in some benchmarks [1,69], the performance advantage for real application is probably more like 10%. The introduction of the 486DX2 processors has more or less obliterated the need for a Weitek 4167, since the DX2 CPUs provide the same performance as the Weitek, as well as the additional features the 80x87 architecture has that the Weitek does not.

There is much noise made about running 286 based machines at 8, 10 or even 12 Megahertz. While running your computer's microprocessor at a faster speed will make a difference, for many tasks the difference is bounded because the limiting factor is often the speed of your input and output devices known collectively as I/O. That these devices slow down the CPU is seen by the typical times involved. 8 MHz means that the CPU goes through 8 million cycles per second. Since a single instruction on the 80xx family of chips takes from two to over twenty cycles, a CPU in the current generation of MS-DOS machine can run at roughly 1 MIPS (millions of instructions per second).

"I observed," he comments, "that people were starting to put these minis out in the operating company, and saw that it was an area of both opportunity and potential problems. I found," he adds, "that some of the people in development had never built an operating system for any computer before; many of them had very little software background. They were coming out of hardware development and telephone technology backgrounds, and yet were starting to build their own operating systems. Having been through that phase of the business myself, it seemed silly to go through it another hundred times, so I started pushing the UNIX operating system into these projects." (Mohr, pg. 22)

Produced by Chips&Technologies, this is the latest entry into the 387- compatible marketplace. Originally announced in October, 1991, it has apparently not been available to end-users before the third quarter of 1992, at least here in Germany. My tests show that its compatibility with Intel products is very good, even for the more arcane features of the 387DX and comparable to the coprocessors from Cyrix. Like these chips, it passes the IEEETEST program without a single failure. It passes, of course, all tests in Chips&Technologies' own compatibility test program, SMDIAG. However, some of the tests (the transcendental functions) in this program are selected in such a way that the C&T 38700 passes while the Cyrix 83D87 or Intel RapidCAD fail, so they are not very useful. (There is also a 'bug' in the test for FSCALE that hides a true bug in the C&T 38700.) My tests show the accuracy of the transcendental functions on the C&T 38700DX varies. Overall, accuracy of the transcendentals is slightly better than on the Intel 387DX.

Thompson and Ritchie presented Bell Labs with proposals to buy them a computer so they could build their own interactive, time sharing operating system. Their proposals weren't acted on. Eventually, Ken Thompson found a little used and obsolete PDP 7 computer. According to Vyssotsky the orphaned PDP-7 computer was a tiny machine, "more nearly in the class of a Commodore 64 than the class of a PC-AT." (Vyssotsky, pg. 60)

Why not take buffers=99? The algorithms that DOS uses are not as efficient as those in commercial caches so that the time it takes to search the buffers to see if the proper sector is in the buffer negates the time saved once the number of buffers becomes too high.

%wrong is the percentage of results that differ from the 'exact' result (infinitely precise result rounded to 64 bits) ULP_hi is the number of results where the returned result was greater than the 'exact' (correctly rounded) result by one ULP (the numeric weight of the last mantissa bit, 2**-63 to 2**-64 depending of the size of the number). ULPs_hi is the number of results where the returned result was greater than the 'exact' result by two or more ULPs. ULP_lo is the number of results where the returned result was smaller than the 'exact' (correctly rounded) result by one ULP (the numeric weight of the last mantissa bit, 2**-63 to 2**-64 depending of the size of the number). ULPs_lo is the number of results where the returned result was smaller than the 'exact' result by two or more ULPs. max ULP err is the maximum deviation of a returned result from the 'exact' answer expressed in ULPs.

Typically the FS segment register is then set up to point to the Weitek's memory block. On the 80486, this technique has severe drawbacks, as using the FS: prefix takes an additional clock cycle, thereby nearly halving the performance of the 4167. Most DOS-based compilers exhibit this problem, so the only way around it is to code in assembly language [75]. The Weitek Abacus 3167 and 4167 are also supported by the UNIX operating system [33].

If you can't locate a provider that has WWW access, then consider using America Online, Compuserve, or Prodigy, or one of the other big companies. Bug them for WWW access and they'll make it part of their services sooner (AOL is working on WWW).

3) Once you've got the correct coprocessor for your system you can start the actual installation process. Turn off the computer's power switch and unplug the power cord from the wall outlet, remove the case, and locate the math coprocessor socket. This socket is always located right next to the main CPU, which can be identified by the printing on top of the chip. (It's also usually one of the biggest chips on the board). The 8078 and 80287 DIL sockets are rectangular sockets with 20 pin holes on each of the longer sides. The 387SX PLCC socket is a square socket that has 17 vertical connector strips on the 'wall' of each side. The 387 PGA socket is square and has two rows of pin holes on each side. The EMC socket for the Weitek 3167 is similar but has three rows of holes on each side. The PGA socket for the Weitek 4167 is also square with three rows of holes on each side. If you can't find the math coprocessor socket, consult your owner's manual, your computer dealer, or a knowledgeable friend.

But he emphasizes, "Perhaps, the most important one was that UNIX was being used as the operating system basis for a bunch of operations support systems in the Bell Operating Companies and we could not afford to let those support systems go down. We put configuration management and all of the associated paraphernalia in place about 1978. (Ibid., pg. 68)

All the programs except for Polyboost will cache several hard disks from the same cache with only one loading of the control software. Polyboost requires multiple loading of its hard disk cache which has two unfortunate consequences: you double the overhead involved with the cache control software and you must dedicate memory as associated with either one hard disk or the other; this isn't useful if you tend to work on one hard disk for a while and then switch to the other. Polyboost's caching is limited to two hard disks. Two of the programs, Quickcache and Speedcache, use an "advanced" EMS call not supported in the current version of the Xebec Amnesia board software which I was using; therefore, I am not able to report their memory usage. In this instance, Speedcache printed an error message and exited without loading and Quickcache crashed the system.

The architecture of the Weitek chips differs significantly from the 80x87. Strictly speaking, the Weitek Abacus 3167 and 4167 are not coprocessors in that they do not transparently extend the CPU architecture; rather, they could be described as highly-specialized, memory-mapped IO devices. But as the term "coprocessor" has been traditionally used for these chips, they will be referred to as such here.

In his account of this period, Dennis Ritchie writes, "Even before the GE-645 Multics machine was removed from the premises, an informal group, led primarily by Ken Thompson, had begun investigating alternatives." ( Ritchie, pg. 1)

The research done at the Labs was concerned with using the computer to automate programming tasks. By a scientific approach to their work and careful attention to detail, Bell Labs researchers determined the essential elements in a design and then created a program to do as simple a job as possible. These simple computer automation tools would then be available to build programs to do more complicated tasks.

In 1969 the Defense Advanced Research Projects Agency (DARPA) funded a research and development project to create an experimental communications network called the ARPANET. Many techniques of modern data communications were developed in the ARPANET. So successful was the ARPANET that in 1975 the network was converted to an operational network. By 1983 the communication techniques developing on the ARPANET were adopted as Military Standards (MIL STD). This suite of networking protocols are known as "TCP/IP" and serve as the basis for the Internet today.

This led to the realization of a need for an operating system. "Vendor operating systems were available as a starting point", he adds "but a number of people had already started to build their own when they realized that what the vendors had was not adequate." (Ibid.)

Academic contributions which were incorporated into research UNIX included the vi editor which was created by Bill Joy at University of California at Berkeley. Describing this phenomena Comer writes:

This is the area in which the arrays are dimensioned and loaded, and some of the special values are set into place. Along with this section is the area beginning with line 9300, this area will expand as we go along adding things to the bare bones of our adventure game. Right now we only have the data that will allow us to move around our "world", and at least know the name of the room that we are in at the time. Later we will expand the 9300+ area to load in other information that will be needed to run a successful game, but for now I will leave the explanation for another article (well, I have to have something to drag this out with).

The coprocessor interface in 80386/80387 systems is very similar to the one found in 286/287 systems. However, to prevent corruption of the coprocessor's contents by programming errors, the IO ports 800000F8h-800000FFh are used, which are not accessible to programs. The CPU/coprocessor interface has been optimized and uses full 32-bit transfers; the interface overhead has been reduced to about 14-20 clock cycles. For some operations on the 387 'clones' that take less than about 16 clock cycles to complete, this overhead effectively limits the execution rate of coprocessor instructions. The only sensible solution to provide even higher floating-point performance was to integrate the CPU and coprocessor functionality onto the same chip, which is exactly what Intel did with the 80486 CPU. The FPU in the 486 also benefits from the instruction pipelining and from the on-chip cache.

Check the pins and make sure none are bent; if some are, you can *carefully* straighten them with needle-nose pliers or tweezers.

Describing the primitive conditions that Thompson faced, Ritchie writes, "At the start, Thompson "did not even program on the PDP itself, but instead used a set of macros for the GEMAP assembler on a GE-635 machine. A postprocesser generated a paper tape readable by the PDP-7. These tapes were carried from the GE machine to the PDP-7 for testing until a primitive UNIX kernel, an editor, an assembler, a simple shell (command interpreter), and a few utilities (like the Unix rm, cat, cp commands) were completed. At this point, the operating system was self- supporting; programs could be written and tested without resort to paper tape, and development continued on the PDP-7 itself." (Ibid., pg 2)

The object in these systems is "to guarantee a minimal acceptable human response time. This challenge has been met by tuning the underlying UNIX system." (Ibid.)

The execution unit of the 80287 is practically identical to that of the 8087; that is, nearly all coprocessor instructions execute in the same number of clock cycles on both coprocessors. However, due to the additional overhead of the 80287's CPU/coprocessor interface (at least ~40 clock cycles), an 8 MHz 80286/80287 combination can have lower floating-point performance than an 8086/8087 system running at the same speed. Additionally, older 286 boards were often configured to run the coprocessor at only 2/3 the speed of the CPU, making use of the ability of the 80287 to run asynchronously: The 80287 has a CKM pin that causes the incoming system clock to be divided by three for the coprocessor if it is tied to ground. The 80286 always divides the system clock by two internally, hence the final ratio of 2/3. However, when the CKM (ClocK Mode) pin is tied high on the 80287, it does not divide the CLK input. This feature has been exploited by the maker of coprocessor speed sockets. These sockets tie CKM high and supply their own CLK signal with a built-in oscillator, thereby allowing the 80287 or compatible to run at a much higher speed than the CPU. With an IIT or Cyrix 287 one can have a 20 MHz coprocessor running with a 8 MHz 80286! Note, however, that the floating- point performance of such a configuration does not scale linearly with the coprocessor clock, since all the data has to be passed through the much slower CPU. If the coprocessor executes mostly simple instructions (such as addition and multiplication), doubling the coprocessor clock to 20 MHz in a 10 MHz system does not show any performance increase at all [24].

Due to recent legal battles with Intel over the right to use the 287 microcode, which AMD lost, AMD may have to discontinue this product (disclaimer: I am not a legal expert).

Note that the use of a highly optimizing compiler producing 32-bit code can give much higher performance for some benchmarks. For example, Intel rates the 33 MHz 386/387DX at 3290 kWhetstones/sec and 0.4 double-precision LINPACK MFLOPS [28,29], and it rates the Intel 486 at 12300 kWhetstones/sec and 1.6 double-precision LINPACK MFLOPS [30]. The compilers used in these benchmarks run by the chip's manufacturer are the ones that give the highest performance available, and sell in the US$ 1000+ price range. Some of them may even be experimental or prereleased versions not available to the general public. The relative performance of one coprocessor to another can and does vary greatly depending on the code generated by compilers. Non-optimizing compilers tend to generate a high percentage of operations which access variables in memory, while optimizing compiler produce code that contains many operations involving registers. Thus it is well possible that coprocessor A beats coprocessor B running benchmark Z if compiled with compiler C, but B beats A when the same benchmark is compiled using compiler D.

IEEETEST reads test vectors from the file TESTVECS and compares the answer returned by the math coprocessor with the answer listed in the test vector. If these answers differ an 'F' is displayed, otherwise a '.'is displayed. Answers can differ due to two types of failures: numeric failures or flag failures. Numeric failures occur when the computed answer has the wrong value. Flag failures occur when the status (invalid operation, divide by zero, underflow, overflow, inexact) is incorrectly identified.

"To some extent," he continues, "that was forced by the fact that they were running on small machines. It may also have been a reaction to the complexity of Multics...It took some very clear thinking on the part of the creators of UNIX to realize that most of that stuff didn't have anything to do with the operating system and didn't have to be included." (Ibid., p. 62 )

"What does industrial computer science research consist of?....Although work for its own sake resulting, for example, in a paper in a learned journal is not only tolerated but welcomed, there is strong though wonderfully subtle pressure to think about problems somehow relevant to our corporation....Indeed, researchers love to find problems to work on; one of the advantages of doing research in a large company is the enormous range of puzzles that turn up....Thus, computer research at Bell Labs has always had a considerable commitment to the world...." -- Dennis Ritchie, "Reflections on Software Research," Communications of the ACM, vol 27, no. 8, August 1984, p. 759

(iii) Design and build software, even operating systems, to be tried early, ideally within weeks. Don't hesitate to throw away the clumsy parts and rebuild them.

Super PC-Kwik has many switches and it may pay to vary some of the switches and do some testing if some aspects of performance seem below what you expect. For example, on the Kaypro 286i, changing the diskette parameter from the default /d+ to /d- resulted in an improvement of the diskettes test by a factor of more than 4!

The 80x87 family of math coprocessors (also known as MCPs [Math CoProcessors], NDPs [Numerical Data Processors], NPXs [Numerical Processor eXtensions], or FPUs [Floating-Point Units], or simply "math chips") are typical examples of such coprocessors. The 80x86 CPUs, with the exception of the 80486 (which has a built-in FPU) can only handle 8, 16, or 32 bit integers as their basic data types. However, many PC-based applications require the use of not only integers, but floating-point numbers. Simply put, the use of floating-point numbers enables a binary representation of not only integers, but also fractional values over a wide range. A common application of floating-point numbers is in scientific applications, where very small (e.g., Planck's constant) and very large numbers (e.g., speed of light) must be accurately expressed. But floating-point numbers are also useful for business applications such as computing interest, and in the geometric calculations inherent in CAD/CAM processing.

Tague was familiar with UNIX and its capabilities and tells the variety of reasons ranging from inadequate file systems, to inadequate performance, to poor user interface that he recommended the initial adoption of UNIX to start the work. "We sold those first application developers on UNIX simply by pointing out that the first job they were going to have to do was program development and that by using the UNIX operating system they could get that job done more easily. I did not argue with them about whether or not they should develop their own operating systems -- knowing in my heart of hearts that once they got on UNIX they wouldn't be able to do any better with the experience and the schedules they had. Indeed, that is what happened." (Tague, pg. 60-1)

Other applications were affected as well, he explains. "in areas like cable and wiring layouts. The algorithms applying to these layouts were well known here at the Laboratories, but they were not the sort of thing you could usefully put into a manual. They were, however, easily put into computer programs. Optimum layouts could thus be generated using the computer to assess all the complicated engineering tradeoffs."(Ibid.)

The remaining tests attempt to check cache overhead or special elements and are not as significant. Test 7 is the time it took to copy 10 files adding to 350K from a hard disk to a floppy and test 8 is the same for a floppy to floppy copy.

Imagine a conversation carried out over a period of hours and days, as if people were leaving messages and responses on a bulletin board. Or imagine the electronic equivalent of a radio talk show where everybody can put their two cents in and no one is ever on hold.

Bell had created the needed field support system to maintain the electronic switching machines and software that were now being upgraded. "Supporting a network of minicomputers would be a significantly different problem, though," August Mohr explains. "Maintaining an operating system is not at all like maintaining an electronic switching system. The minicomputers had different reliablity demands, requiring a different support structure in the organization -- one that did not yet exist in any form. In many ways, the operations group was breaking new ground," writes Mohr. (Ibid.)

A coprocessor in the traditional sense is a processor, separate from the main CPU, that extends the capabilities of a CPU in a transparent manner. This means that from the program's (and programmer's) point of view, the CPU and coprocessor together look like a single, unified machine.

If you already a member of America Online, Compuserve, or the like, look for their Internet services. This should be pretty easy since the Internet is very popular these days. For example, with Americal Online, from the main menu go to the "Internet Connection."

"Many universities contributed to UNIX. At the University of Toronto, the department acquired a 200-dt-per-inch printer/plotter and built software that used the printer to simulate a phototypesetter. At Yale University, students and computer scientists modified the UNIX shell. At Purdue University, the Electrical Engineering Department made major improvements in performance, producing a version of UNIX that supported a larger number of users. Purdue also developed one of the first UNIX computer networks. At the University of California at Berkeley, students developed a new shell and dozens of smaller utilities. By the late 1970s, when Bell Labs released Version 7 UNIX, it was clear that the system solved the computing problems of many departments, and that it incorporated many of the ideas that had arisen in universities. The end result was a strengthened system. A tide of ideas had started a new cycle, flowing from academia to an industrial laboratory, back to academia, and finally moving on to a growing number of commercial sites." (Comer, p. 43)

The Internet is the catch-all word used to describe the massive world-wide network of computers. The word "internet" literally means "network of networks" and is composed of thousands of smaller regional networks scattered throughout the planet. On any given day it connects roughly 20 million users in over 50 countries.

Before I wrote my notes on UNIX, most people thought of operating systems as huge and inaccessible. Because I had been at Burroughs, I knew that people could get to learn a whole program if they spent some time working at it. I knew it would be possible for one person to effectively become an expert on the whole system. The Edition 6 UNIX code contained less than 10,000 lines, which positioned it nicely to become the first really accessible operating system." (Lions, p. 52-3)

// rough average of the timings given for different numeric formats by Weitek. Note that these conversions routines do much more work than the FBLD and FBSTP instructions provided by the 80x87 coprocessors. FBLD and FBSTP are useful for conversion routines but quite a bit of additional code is need for this purpose.

Explaining the surprising popularity that UNIX achieved despite its grassroots distribution system, McIlroy writes, "Therein lies the genius of Unix, which, without a sales force, and without the support of hardware makers, was enthusiastically adopted around the world ..." ("Unix on My Mind")

To automate this maintenance work, Mike Lesk, one of the Bell Labs computer researchers, proposed an automated maintenance system that would make it possible to have the research computer call up the computers in the departments and automatically deliver updated software and test that it worked on the remote computer.

Among the 80x87 coprocessors, the IEEE-754 Standard for Binary Floating-Point Arithmetic [10,11] was first fully implemented by Intel's 387 coprocessor [17]. Among other things, this means that the add, subtract, multiply, divide, remainder, and square root operations always deliver the 'exact' result. By 'exact', the standard means that the coprocessor always delivers the machine number closest to the real result, which may not always be representable exactly in the available numeric format. The 80387 implements the single, double, and double extended formats as specified in the IEEE standard, as well as all functions required by it [17].

The basic data type used by all 80x87 coprocessors is an 80-bit long floating-point number. This data type (called "temporary real" or "double extended precision") can directly represent numbers which range in size between 3.36*10^-4932 and 1.19*10^4932 (3.65*10^-4951 to 1.19*10^4932 including denormal numbers) where '^' denotes the power operator. (For those familiar with floating-point formats, this format has 64 mantissa bits, 15 exponent bits and 1 sign bit, for the total of 80 bits.) This format provides a precision of about 19 decimal places. 80x87s can also handle additional data types that are converted to/from the internal format upon being loaded or stored to/from the coprocessor. These include 16 bit, 32 bit, and 64 bit integers as well as a 18 digit BCD (binary coded decimal) data type occupying 10 bytes and providing 18 decimal digits.

Another 8087 coprocessor instruction can only be started if the previous one has been completed in the NEU (numerical execution unit) of the 8087. To prevent the 8086 from decoding a new coprocessor instruction while the 8087 is still executing the previous coprocessor instruction, a coding mechanism is employed: All 8087-capable compilers and assemblers automatically generate a WAIT instruction before each coprocessor instruction. The WAIT instruction tests the CPU's /TEST pin and suspends execution until its input becomes "LOW". In all 8086/8087 systems, the 8086 /TEST pin is connected to the 8087 BUSY pin. As long as the NEU executes a coprocessor instruction, it forces its BUSY pin "HIGH"; thus, the WAIT opcode preceding the coprocessor instruction stops the CPU until any still-executing coprocessor instruction has finished.

The collaborative project by GE, MIT and AT&T to create a computer operating system that would be called Multics (1965-68) was to "show that general-purpose, multiuser, timesharing systems were viable." (See Douglas Comer, "Pervasive Unix: Cause for Celebration," Unix Review, October, 1985, p. 42) Based on the results of research gained at MIT using the Compatible Time-Sharing System (CTSS), AT&T and G.E. agreed to work with MIT to build a "new hardware, a new operating system, a new file system, and a new user interface." (Ibid.) Though the project proceeded slowly and it took several additional years to develop Multics, Doug Comer, a Professor of Computer Science at Purdue University, explains that "fundamental issues were uncovered, new approaches were explored and new mechanisms were invented." (Ibid) The most important, he explains, was that "participants and observers alike became devoted to a new form of computing (the interactive, multiuser, timesharing system.). As a result, the Multics project dominated computer systems research for many years, and many of its results are still considered seminal."(Ibid.)

Ok, now we start to take the program apart and follow a command through the parser and try to figure out how the thing works. Also I'll try to point out a couple of places that need some special attention. Let's begin with the program lines between 100 and 900.

Ok, we have set up the arrays and loaded all of the various background elements that control our world - now what? At this point we are at line 910 and we find that the name of the current room is displayed on the screen (which room we are in is set in line 110 with L=4). Then it tries to decide if EXTRA is true, which it is not at this time (it's workings will be described later). So, it's off to line 9000 and the real workhorse around here -- the PARSER (see it even says so). Here's where I really get into problems and will have to have Aaron check my work, he wrote it and he is the whiz with strings (and graphics and figuring out programs and - well, enough) all I know is that I can make it do what I want by putting in the commands. Anyway, we may all learn something here ---

Due to the considerable amount of heat produced by these chips, and taking into consideration the slow air flow provided by the fan in garden-variety PC tower cases, I recommend an extra fan directly above the CPU for safer operation. If you measure the surface temperature of an 486DX after some time of operation in a normal tower case without extra cooling, you may well come up with something like 80-90 degrees Celsius (that is 175-195 degrees Fahrenheit for those not familiar with metric units) [54,55]. You don't need the well known (and expensive) IceCap[tm] to effectively cool your CPU; a simple fan mounted directly above the CPU can bring the temperature of the chip down to about 50-60 degrees Celsius (120-140 degrees Fahrenheit), depending on the room temperature and the temperature within the PC case (which depends on the total power dissipation of all the components and the cooling provided by the fan in the system's power supply). According to a simple rule known as Arrhenius' Law, lowering the temperature by 10 degrees Celsius slows down chemical reactions by a factor of two, so lowering the temperature of your CPU by 30 degrees should prolong the life of the device by a factor of eight, due to the slower ageing process. If you are reluctant to add a fan to your system because of the additional noise, settle for a low-noise fan like those available from the German manufacturer Pabst (this is not meant to be an advertisement; I am just the happy owner of such a fan, and have no other connections to the firm).

(Note that the EMC87 is *not* compatible with Weitek's Abacus coprocessor. They both use the same CPU interface technique [memory mapping], but while the EMC87 uses the standard 387 instruction set, the Weitek Abacus coprocessors use a different instruction set entirely its own.)

This information comes from sites all over the globe connected to the Internet. So let's talk a little about the Internet and the various information services you can use to get skydiving information.

Ritchie explains that Ken Thompson was attempting to create a programming environment which included "many of the innovative aspects of Multics," such as "an explicit notion of a process as a locus of control, a tree-structured file system, a command interpreter as a user-level program, simple representation of text files, and generalized access to devices." (Ritchie, p. 1-2)

"One very positive effect, however" writes Lions, "is that the number of universities using UNIX and the lack of any formal support forced us to band together into AUUG. (Australian unix users group -ed) The connections we have thereby made have created and cemented bonds between people in the different departments. UNIX has been a very unifying influence for computer science within Australia. This cannot be overestimated."(Ibid., pg. 57)

The WWW is a relatively new information system to the Internet. But because it incorporates all the existing services like Usenet news, FTP, and Gopher, the Web is very popular. In December of 1994, the Skydive! site saw more than 14 thousand transactions for various information. And the graphical interface makes it easy to navigate the Internet. When Vice President talks about the Information Super-Hypeway, he's talking about the WWW.

Tague's backing of UNIX, as a development system for operations, was not just a personal preference. "I had every confidence in the people who built it because I'd worked with them on Multics," he explained. "With their experience and training, I figured they could build a much better operating system than somebody who's building one for the first time, no matter how smart that person is." (Mohr, pg 22)

Because of the inherent dangers in caching and because caching involves modifications of the disk BIOS, you need to be extremely careful if your disk setup is non standard. You may need to consult the vendors. Super PC-Kwik explicitly says not to use it if you have a Bernoulli Box while Vcache says that it supports these devices. The publishers of Vcache warned me not to use Vcache with my 60 Meg Priam disk which I partitioned with Priam's software into two 30 Meg drives; only large disks handled with the VFEATURE program they they publish are compatible with Vcache. On the other hand, Super PC-Kwik warns against disks with non- standard sector sizes but said that it should work with software making multiple standard DOS partitions. I was warned that they had not tested the program with the Priam software but I can report that it worked perfectly. Here, my advice is to check with the publishers, be sure that you are backed up and run CHKDSK several times a day when you first try a caching program with anything non-standard.

Two of the programs Speedcache and Quickcache load as device drivers rather than as com files. Conventional wisdom would hold that device drivers are somewhat less prone to compatibility problems but I don't know if that is valid in these cases.

RapidCAD's use of the standard 386 bus interface causes instructions that access memory to execute at about the same speed as on the 386. The integer performance on the RapidCAD is definitely limited by the low memory bandwidth provided by this interface (2 clock cycles per bus cycle) and the lack of an internal cache. CPU instructions often execute faster than they can be fetched from memory, even with a big and fast external cache. Therefore, the integer performance of the RapidCAD exceeds that of a 386 by *at most* 35%. This value was derived by running some programs that use mostly register-to-register operations and few memory accesses, and is supported by the SPEC ratings that Intel reports for the 386-33 and the RapidCAD-33: while the 386-33 has a SPECint of 6.4, the RapidCAD has a SPECint of 7.3 [28], a 14% increase. (Note that these tests used the old [1989] SPEC benchmarks suite.)

If you have a demand for high floating-point performance, you should consider buying a full 486-based system, rather than a 386-based system with an additional coprocessor. Consider: A 386/33 MHz motherboard currently sells for ~US$ 270; together with the coprocessor, the cost totals ~US$ 350. A 486/33 MHz ISA motherboard sells for US$ 650. While this means that the 486 system is 85% more expensive than the 386/387 system, it also provides 100% more integer and floating-point performance (twice the performance), giving it better price/performance for math-intensive applications. As prices for 486 chips fall in the future, the price difference between these two systems should become even smaller.

Thus by 1980, a survey conducted by the Computer Science Research Network (CSNET) of academic institutions to find out what computer system they used, found that "over 90 percent of all departments were served by one or more UNIX systems." (Comer, pg. 42)

The second method to interface an emulator is only available on 286/386/486 machines. If the emulation bit in the machine status word of these processors is set, the processors will generate an interrupt 7 whenever a coprocessor instruction is encountered. The vector for this interrupt will have been set up to point at an emulation package that decodes the instruction and performs the desired operation. This approach has the advantage that the emulator doesn't have to be included in the program code, but can be loaded once (as a TSR or device driver) and then used by every program that requires a coprocessor. Emulation via interrupt 7 is transparent, which means that programs containing coprocessor instructions execute just like a coprocessor was present, only slower. This approach is taken by the public domain EM87 emulator, the shareware program Q387, and the commercial Franke387 emulator, for example. Even programs that require a coprocessor to run like AutoCAD are 'fooled' to believe that a coprocessor is present with emulators using

(( Q387 is an emulator that is distributed as a shareware program by Quickware of Austin, Texas. As the name implies, this emulator uses 386 specific code and supports the full 387 instruction set. The program is about 330 kByte in size and loads completely into extended memory, using absolutely no DOS memory. It is loaded as a TSR and requires an EMM (expanded memory manager) to be present. The emulation uses the INT 7 mechanism. The version of Q387 used was 3.0a.

I tested some of the transcendental functions of the Cyrix 387+ and found the relative error to be always below 0.6 ULPs. Cyrix also claims that its transcendental functions satisfy the monotonicity criterion [13], a claim not made by any of the competitors, which does not mean that the transcendental functions on the other 387-compatibles may not be monotonic, too. Monotonicity means that for all x1 > x2, it always follows that f(x1) >= f(x2) for an increasing function like sin on [0..pi/4]. Likewise, for a decreasing function like cos on [0..pi/4], for all x1 > x2, it follows that f(x1) <= f(x2).

The Weitek's register file consists of 31 32-bit registers, each one capable of holding an IEEE single-precision number. Pairs of consecutive single- precision registers can also be used as 64-bit IEEE double-precision registers; thus there are 15 double-precision registers. The Weitek register file has the standard organization like the register files in the 80386, not the special stack-like organization of the 80x87 coprocessors.

FTP is a very old Internet system and is somewhat hard to use. These days, most people browse FTP sites via the World Wide Web, the most popular Internet system today.

What are the disadvantages of using buffers for a cache? First there is the issue of dirty buffers. Actually, just using a commercial cache doesn't effect this since caches still use DOS for reading and writing and so the DOS buffers will still get used. However, a cache that lets you decrease the number of buffers that you use will force DOS to write its buffers to disk more often because of space considerations. Another disadvantage of DOS buffers is that since it is based on 512 byte chunks, if a program requests more than that at once, DOS will always go to disk and not check to see if the request is residing in its buffers. Finally, there is the size issue that I mentioned; for really large caches, you'll need a commercial program.

"The network," he points out, "is the direct result of a community that supports its members and in turn is nurtured by the ones it serves. The community is a reasonably democratic one, reasonably open to new ideas, resonably open to change, and reasonably generous with its benefits."(Ibid.)

First, the test results illustrate the importance of increasing buffers above the default 2 or 3 if you are not using a cache; they also illustrate that there is a break point where too many buffers can hurt you. On things that caches do well (Tests 1-4), caches are competitive with RAM disks.

"A parade of visitors came to marvel at the system and to copy it. The makers of our 1972 model phototypesetter goggled when they saw the paper tape input replaced by wires straight from a computer. On-line PicturePhone[r] service caught attention. Synthetic speech was initiated by a memorable `Come here, Watson' event when words typed in a remote office range out clearly in the lab: `It sounds better over the telephone.' The computer's readings and misreadings became a constant crowd pleaser. There was great, if somewhat conspiratorial, excitement over a stealthy version of the C compiler that would recognize and silently bug the Unix login program and would propagate the ability through future generations of the compiler itself....No trace of the bug appeared in source code." (Ibid.)

Additionally, some parts of the coprocessor architecture, like the status register, are often not or only partially emulated. Some emulators do not conform to the IEEE-754 standard in their implementation of the basic arithmetic functions, while the hardware coprocessors do. Also, they sometimes lack the support for denormals (a special class of floating-point numbers) although it is required by the standard. Not all the 80x87 emulators support rounding control and precision control, also features required by IEEE-754. Most of these omissions are aimed at making the emulator faster and smaller. Because of the performance gap and these other shortcomings of coprocessor emulators, a real coprocessor is a must for anybody planning to do some serious computations. (At today's prices, this shouldn't pose much of a problem to anybody!)

In any 80x86 system with an 80x87 math coprocessor, CPU instructions and coprocessor instructions are executed concurrently. This means that the CPU can execute CPU instructions while the coprocessor executes a coprocessor instruction at the same time. The concurrency is restricted somewhat by the fact that the CPU has to aid the coprocessor in certain operations. As the CPU and the coprocessor are fed from the same instruction stream and both instruction streams may operate on the same data, there has to be a synchronizing mechanism between the CPU and the coprocessor.

With regard to the accuracy of transcendental functions, Cyrix claims that the relative error of the transcendental functions on its 83D87 coprocessor never exceeds 0.5 ULP of the double extended format [13] (ULP = Unit in the Last Place, numeric weight of the least significant mantissa bit). This means that the maximum relative error is below 2**-64, while Intel's published error limit for the 80387 is 2**-62. While Intel uses a modified CORDIC algorithm [18,19] to compute the transcendental functions, Cyrix uses rational approximations that utilize their chip's very fast array multiplier. (For an explanation why this approach is superior to CORDIC with today's technology, see [61].) Also, Cyrix uses an internal 75 bit data path for the mantissa [15], so intermediate computations in the generation of transcendental function values will enjoy some additional accuracy over the 64 bits provided by the double extended format. Using 75 mantissa bits also provides an advantage over other coprocessors like the Intel 387DX and ULSI 83C87 which use only a 68 bit mantissa data path [58,59].

This shows that performance of the same coprocessor can vary by up to ~10% depending on the chipset used on your board, at least for 386 motherboards (similar numbers for 286, 386SX, and 486 are, unfortunately, not available). The benchmarks for this article were run on a motherboard with the Forex chip set, one of the fastest 386 chip sets available, and not only with respect to floating-point performance [35].

Note that for spreadsheets and databases, a coprocessor only helps if some kind of floating-point computation is performed; this is true more often for spreadsheets than for databases. Also note that the speed of many programs depends quite heavily on factors such the speed of the graphics adapter (CAD) or the disk performance (databases), so the computational performance is only a (small) part of the total performance of the application. There are some programs that won't run without a coprocessor, among them AutoCAD (R10 and later) and Mathematica.

Polyboost and Vcache come with screen speedup programs; Polyboost also has a keyboard speedup program which I did not test. Table 3 shows tests that I did in typing the same 111K file to the screen that I used in my earlier articles on console software. RAW is a program which turns on DOS' raw mode (see February Monitor). The tests with the CRTBOST and EGABOOST programs that come with Polyboost are done with their optional parameters set to 1 and to 5. Setting this parameter to 6 is equivalent to setting it to 5 and turning RAW on. Setting the parameter to 1 is recommended for most users. Times are given in seconds. For comparison, times are given for some of the other screen management programs that I have considered. Fansi Console has a "quick" parameter which can be turned on and off.

By 1970, Ritchie writes, the UNIX researchers were "able to acquire a new DEC PDP-11. The processor," he remembers, "was among the first of its line delivered by DEC, and three months passed before its disk arrived." (Ritchie, p. 5) Soon after the machine's arrival and while "still waiting for the disk, Thompson," Ritchie recalls, "recoded the Unix kernel and some basic commands in PDP assembly language. Of the 24K bytes of memory on the machine, the earliest PDP-11 Unix system used 12K bytes for the operating system, a tiny space for user programs, and the remainder as a RAM disk." (Ibid., p. 5) "By 1971," Ritchie writes, "our miniature computer center was beginning to have users. We all wanted to create interesting software more easily. Using assembler was dreary enough that B, despite its performance problems, had been supplemented by a small library of useful service routines and was being used for more and more new programs."(Ibid., p. 6)

COMPTEST is in the public domain and comes with complete source code. It is available via anonymous ftp from garbo.uwasa.fi and additional ftp sites that mirror garbo.


